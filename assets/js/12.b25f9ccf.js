(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{431:function(t,s,a){"use strict";a.r(s);var n=a(65),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"算法图解笔记"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#算法图解笔记"}},[t._v("#")]),t._v(" 算法图解笔记")]),t._v(" "),a("h2",{attrs:{id:"第一章-算法简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第一章-算法简介"}},[t._v("#")]),t._v(" 第一章:算法简介")]),t._v(" "),a("h3",{attrs:{id:"二分查找"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二分查找"}},[t._v("#")]),t._v(" 二分查找")]),t._v(" "),a("h4",{attrs:{id:"定义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#定义"}},[t._v("#")]),t._v(" 定义")]),t._v(" "),a("ul",[a("li",[t._v("二分查找是一种算法，其输入是一个"),a("strong",[t._v("有序")]),t._v("的元素列表（必须有序的原因稍后解释）。如果要查找的元素包含在列表中，二分查找返回其位置；否则返回null。")])]),t._v(" "),a("h4",{attrs:{id:"具体内容"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#具体内容"}},[t._v("#")]),t._v(" 具体内容")]),t._v(" "),a("ul",[a("li",[t._v("假如有一个1-100的数组,现在随便想一个数,猜出这个数在数组中的索引.")]),t._v(" "),a("li",[t._v("如果从1开始一个个猜就是简单查找,也叫傻找.")]),t._v(" "),a("li",[t._v("二分查找就是"),a("strong",[t._v("每次把数组分成两份,猜中间数,这样一次可以排除一半的数组范围")]),t._v(".")])]),t._v(" "),a("h4",{attrs:{id:"优点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#优点"}},[t._v("#")]),t._v(" 优点")]),t._v(" "),a("ul",[a("li",[t._v("一般而言，对于包含n个元素的列表，用二分查找最多需要"),a("code",[t._v("log2n")]),t._v("步，而简单查找最多需要"),a("code",[t._v("n")]),t._v("步。")])]),t._v(" "),a("blockquote",[a("p",[t._v("你可能不记得什么是对数了，但很可能记得什么是幂。"),a("code",[t._v("log10 100")]),t._v("相当于问“将多少个10相乘的结果为100”。答案是两个：10 × 10 = 100。因此，"),a("code",[t._v("log10 100")]),t._v(" = 2。对数运算是幂运算的逆运算。")]),t._v(" "),a("p",[t._v("简单点说就是"),a("code",[t._v("log2n")]),t._v("就是"),a("strong",[t._v("2的几次方等于n")]),t._v(",这个几次方就是具体表达的数字")])]),t._v(" "),a("h4",{attrs:{id:"练习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[t._v("1.1 假设有一个包含128个名字的有序列表，你要使用二分查找在其中查找一个名字，请\n问最多需要几步才能找到？\n"),a("ul",[a("li",[t._v("答:7步,2的7次方=128")])])]),t._v(" "),a("li",[t._v("1.2 上面列表的长度翻倍后，最多需要几步？\n"),a("ul",[a("li",[t._v("答:8步")])])])]),t._v(" "),a("h4",{attrs:{id:"运行时间"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#运行时间"}},[t._v("#")]),t._v(" 运行时间")]),t._v(" "),a("ul",[a("li",[t._v("一般来讲我们写代码肯定是想要缩短运行时间,追求最高效率")]),t._v(" "),a("li",[t._v("最简单的逐个查找的算法,包含"),a("strong",[t._v("多少个数字就需要猜多少次")]),t._v(",最多需要猜测的次数与列表长度相同，这被称为"),a("strong",[t._v("线性时间")]),t._v("（linear time）。")]),t._v(" "),a("li",[t._v("二分查找则不同,如果列表包含100个元素，最多要猜7次；如果列表包含40亿个数字，最多需猜32次。"),a("strong",[t._v("二分查找的运行时间为对数时间")]),t._v("（或log时间）。")])]),t._v(" "),a("h3",{attrs:{id:"大o表示法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大o表示法"}},[t._v("#")]),t._v(" 大O表示法")]),t._v(" "),a("ul",[a("li",[t._v("大O表示法指出了算法的速度有多快,因为经常要使用别人给的算法,所以知道速度就很重要,这决定我们挑选出最合适的算法.")])]),t._v(" "),a("h4",{attrs:{id:"算法的运行时间以不同的速度增加"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#算法的运行时间以不同的速度增加"}},[t._v("#")]),t._v(" 算法的运行时间以不同的速度增加")]),t._v(" "),a("ul",[a("li",[t._v("仅知道算法需要多长时间才能运行完毕还不够，还需知道"),a("strong",[t._v("运行时间如何随列表增长而增加")]),t._v("。这正是大O表示法的用武之地。")]),t._v(" "),a("li",[t._v("大O表示法指出了算法有多快。并非以秒为单位的速度。而是让你能够"),a("strong",[t._v("比较操作数")]),t._v("，它指出了"),a("strong",[t._v("算法运行时间的增速")]),t._v("。")]),t._v(" "),a("li",[t._v("表示方法如下:"),a("code",[t._v("O(n)")]),t._v(",以大写字母O开头,后边跟一个括号,括号里的数字就是操作数,当然,数字越大表示算法速度越慢,越小表示算法速度越快.")])]),t._v(" "),a("h4",{attrs:{id:"理解不同的大-o-运行时间"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#理解不同的大-o-运行时间"}},[t._v("#")]),t._v(" 理解不同的大 O 运行时间")]),t._v(" "),a("ul",[a("li",[t._v("一张纸上画出16个格子,可以一个个格子画,那就需要16次画完,如果是对折,只需要对折4次就可以得到16个格子")]),t._v(" "),a("li",[t._v("算法1的运行时间为"),a("code",[t._v("O(n)")]),t._v("，算法2的运行时间为"),a("code",[t._v("O(log n)")]),t._v("。")])]),t._v(" "),a("h4",{attrs:{id:"大-o-表示法指出了最糟情况下的运行时间"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大-o-表示法指出了最糟情况下的运行时间"}},[t._v("#")]),t._v(" 大 O 表示法指出了最糟情况下的运行时间")]),t._v(" "),a("ul",[a("li",[t._v("简单查找法也有可能我们第一次就找到了要找的内容,运行时间是"),a("code",[t._v("O(n)")]),t._v("还是"),a("code",[t._v("O(1)")]),t._v("呢？")]),t._v(" "),a("li",[t._v("简单查找运行时间总是为"),a("code",[t._v("O(n)")]),t._v("。一次找到是最佳情形,但是"),a("strong",[t._v("大O表示法说的是最糟的情形")]),t._v("。你知道"),a("strong",[t._v("简单查找的运行时间不可能超过"),a("code",[t._v("O(n)")])]),t._v("。")])]),t._v(" "),a("h4",{attrs:{id:"一些常见的大-o-运行时间"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一些常见的大-o-运行时间"}},[t._v("#")]),t._v(" 一些常见的大 O 运行时间")]),t._v(" "),a("ul",[a("li",[t._v("下面按从快到慢的顺序列出了你经常会遇到的5种大O运行时间。\n"),a("ul",[a("li",[a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(")，也叫对数时间，这样的算法包括二分查找。")]),t._v(" "),a("li",[a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")，也叫线性时间，这样的算法包括简单查找。")]),t._v(" "),a("li",[t._v("O*("),a("em",[t._v("n")]),t._v(" * log "),a("em",[t._v("n")]),t._v(")，这样的算法包括第4章将介绍的快速排序——一种速度较快的排序算法。")]),t._v(" "),a("li",[a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v("2)，这样的算法包括第2章将介绍的选择排序——一种速度较慢的排序算法。")]),t._v(" "),a("li",[a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v("!)，这样的算法包括接下来将介绍的旅行商问题的解决方案——一种非常慢的算法。")])])]),t._v(" "),a("li",[t._v("还有其他的运行时间，但这5种是最常见的。")]),t._v(" "),a("li",[t._v("当前，我们获得的主要启示如下。\n"),a("ul",[a("li",[t._v("算法的速度指的并非时间，而是操作数的增速。")]),t._v(" "),a("li",[t._v("谈论算法的速度时，我们说的是随着输入的增加，其运行时间将以什么样的速度增加。")]),t._v(" "),a("li",[t._v("算法的运行时间用大O表示法表示。")]),t._v(" "),a("li",[a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(")比"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")快，当需要搜索的元素越多时，前者比后者快得越多。")])])])]),t._v(" "),a("h4",{attrs:{id:"旅行商"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#旅行商"}},[t._v("#")]),t._v(" 旅行商")]),t._v(" "),a("ul",[a("li",[t._v("**O(n!)**是一种速度特别慢的算法,它是真实存在的,就是这个计算机科学领域非常著名的旅行商问题,其计算时间增加得非常快，而有些非常聪明的人都认为没有改进空间。")]),t._v(" "),a("li",[t._v("有一位旅行商。他需要前往5个城市。")]),t._v(" "),a("li",[t._v("对于每种顺序，他都"),a("strong",[t._v("计算总旅程")]),t._v("，再"),a("strong",[t._v("挑选出旅程最短的路线")]),t._v("。5个城市有120种不同的排列方式。因此，在涉及5个城市时，解决这个问题需要执行120次操作。涉及6个城市时，需要执行720次操作（有720种不同的排列方式）。涉及7个城市时，需要执行5040次操作！")]),t._v(" "),a("li",[t._v("推而广之，涉及"),a("em",[t._v("n")]),t._v("个城市时，需要执行"),a("em",[t._v("n")]),t._v("!（"),a("strong",[t._v("n的阶乘")]),t._v("）次操作才能计算出结果。因此运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v("!)，即阶乘时间。除非涉及的城市数很少，否则需要执行非常多的操作。如果涉及的城市数超过100，根本就不能在合理的时间内计算出结果——等你计算出结果，太阳都没了。")]),t._v(" "),a("li",[a("strong",[t._v("这是计算机科学领域待解的问题之一")]),t._v("。对于这个问题，"),a("strong",[t._v("目前还没有找到更快的算法")]),t._v("，有些很聪明的人认为这个问题根本就没有更巧妙的算法。")])]),t._v(" "),a("h3",{attrs:{id:"小结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("二分查找的速度比简单查找快得多。")]),t._v(" "),a("li",[t._v("O(log n)比O(n)快。需要搜索的元素越多，前者比后者就快得越多。")]),t._v(" "),a("li",[t._v("算法运行时间并不以秒为单位。")]),t._v(" "),a("li",[t._v("算法运行时间是从其增速的角度度量的。")]),t._v(" "),a("li",[t._v("算法运行时间用大O表示法表示。")])]),t._v(" "),a("h2",{attrs:{id:"第二章-选择排序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第二章-选择排序"}},[t._v("#")]),t._v(" 第二章:选择排序")]),t._v(" "),a("h3",{attrs:{id:"内存的工作原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#内存的工作原理"}},[t._v("#")]),t._v(" 内存的工作原理")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("内存就像一个有很多抽屉的大柜子,每个抽屉都有自己的地址")])]),t._v(" "),a("li",[t._v("需要将数据存储到内存时，你请求计算机提供存储空间，计算机给你一个存储地址。需要存储多项数据时，有两种基本方式——数组和链表。")])]),t._v(" "),a("h3",{attrs:{id:"数组和链表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数组和链表"}},[t._v("#")]),t._v(" 数组和链表")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("数组在内存中是相连的")]),t._v(",比如现在第一排的柜子里前三个位置空着,你放进三个东西组成一个数组,它们是相连的.但是如果你"),a("strong",[t._v("想添加第四个数组元素")]),t._v(",恰好"),a("strong",[t._v("第四个柜子被人占了")]),t._v(",那你只能在所有柜子中"),a("strong",[t._v("找到相连的四个抽屉把它们转移")]),t._v("过去")]),t._v(" "),a("li",[t._v("所以"),a("strong",[t._v("数组新增元素很慢")]),t._v(',有一个解决办法,就是"'),a("strong",[t._v("预留座位")]),t._v('",即时你只有三个东西需要存,也找计算机提供10个位置,这样只要你的东西不超过10个,就无须转移位置,但是也'),a("strong",[t._v("存在两个缺点")]),t._v(" "),a("ul",[a("li",[t._v("你请求的额外位置可能用不上,然后别人也用不了,浪费内存")]),t._v(" "),a("li",[t._v("一旦超过10个还是得转移")])])])]),t._v(" "),a("h4",{attrs:{id:"链表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#链表"}},[t._v("#")]),t._v(" 链表")]),t._v(" "),a("ul",[a("li",[t._v("链表中的元素可以存在内存的任意地方.")]),t._v(" "),a("li",[a("strong",[t._v("每个元素都存储了下一个元素的地址")]),t._v(",从而把一系列随机内存地址串了起来")]),t._v(" "),a("li",[t._v("是在"),a("strong",[t._v("添加元素")]),t._v("的时候,同时"),a("strong",[t._v("给末尾的元素添加上新元素的内存地址")]),t._v(".这样添加元素就很容易了.")]),t._v(" "),a("li",[t._v('这就解决了数组添加元素的问题,假如六个人一起看电影,但是没有六个挨在一起的座位,甚至有时候你要为数组分配一万个位置,但是内存中没有一万个连续的位置,就无法分配内存,链表相当于"分开坐",'),a("strong",[t._v("只要有足够的内存空间就可以分配")]),t._v(".")])]),t._v(" "),a("h4",{attrs:{id:"数组"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数组"}},[t._v("#")]),t._v(" 数组")]),t._v(" "),a("ul",[a("li",[t._v("某些漫画网站很讨厌,每一页一张图,假如你想看第十张你得连续点击九次下一张.")]),t._v(" "),a("li",[a("strong",[t._v("链表")]),t._v("就有类似问题,在读取最后一个元素时,不能直接读取,因为你不知道它的地址,所以你"),a("strong",[t._v("必须先读取第一个元素拿到第二个元素地址,以此类推直到从倒数第二个元素拿到最后一个元素的地址")]),t._v(".")]),t._v(" "),a("li",[t._v("需要"),a("strong",[t._v("读取所有元素时链表效率很高")]),t._v(",但是如果需要"),a("strong",[t._v("跳跃读取,效率就很低")]),t._v(".")]),t._v(" "),a("li",[t._v("数组就不一样了,"),a("strong",[t._v("数组是连续的")]),t._v(",从0到n,所以"),a("strong",[t._v("随机读取元素时数组效率很高")]),t._v(".可以通过我们想读取的元素索引迅速找到该元素")])]),t._v(" "),a("h4",{attrs:{id:"术语"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#术语"}},[t._v("#")]),t._v(" 术语")]),t._v(" "),a("ul",[a("li",[t._v("数组编号从0开始而不是1")]),t._v(" "),a("li",[t._v("元素位置称为索引.")]),t._v(" "),a("li",[t._v("问题：在数组中插入元素时，为何运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")呢？假设要在数组开头插入一个元素，你将如何做？这需要多长时间？请阅读下一节，找出这些问题的答案！\n"),a("ul",[a("li",[t._v("因为大O表示法预估的是最差的情况,最差的情况下数组插入元素时连续空间不够,整个数组需要被复制到新的位置,所以是O(n).开头也是O(n),因为数组中所有元素都得挨个后移.")])])]),t._v(" "),a("li",[t._v("练习\n"),a("ul",[a("li",[t._v("2.1 假设你要编写一个记账的应用程序。")]),t._v(" "),a("li",[t._v("你每天都将所有的支出记录下来，并在月底统计支出，算算当月花了多少钱。因此，你执行的插入操作很多，但读取操作很少。该使用数组还是链表呢？\n"),a("ul",[a("li",[t._v("插入很多读取很少,使用链表,链表插入效率高,为O(1)")])])])])])]),t._v(" "),a("h4",{attrs:{id:"在中间插入"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#在中间插入"}},[t._v("#")]),t._v(" 在中间插入")]),t._v(" "),a("ul",[a("li",[t._v("在中间插入时,使用链表,插入元素很简单,只需要改变插入位置前面那个元素指向的地址,但是数组就必须将后面的元素都后移.")]),t._v(" "),a("li",[t._v("没有足够空间还得把整个数组复制到其它地方,因此,中间插入元素链表是更好的选择.")])]),t._v(" "),a("h4",{attrs:{id:"删除"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#删除"}},[t._v("#")]),t._v(" 删除")]),t._v(" "),a("ul",[a("li",[t._v("如果删除元素,链表也是更好的元素,只需改变修改前一个元素指向的地址即可.")]),t._v(" "),a("li",[t._v("而数组就必须把删除后的元素向前移.")]),t._v(" "),a("li",[t._v("但是"),a("strong",[t._v("不同于插入,数组删除总是能成功")]),t._v(".")]),t._v(" "),a("li",[a("strong",[t._v("仅当能够立即访问要删除的元素时，删除操作的运行时间才为"),a("em",[t._v("O")]),t._v("(1)")]),t._v("。通常我们都记录了链表的第一个元素和最后一个元素，因此删除这些元素时运行时间为"),a("em",[t._v("O")]),t._v("(1)。")])]),t._v(" "),a("p",[t._v("练习")]),t._v(" "),a("ul",[a("li",[t._v("2.2 假设你要为饭店创建一个接受顾客点菜单的应用程序。这个应用程序存储一系列点菜单。服务员添加点菜单，而厨师取出点菜单并制作菜肴。这是一个点菜单队列：服务员在队尾添加点菜单，厨师取出队列开头的点菜单并制作菜肴。你使用数组还是链表来实现这个队列呢？（提示：链表擅长插入和删除，而数组擅长随机访问。在这个应用程序中，你要执行的是哪些操作呢？）\n"),a("ul",[a("li",[t._v("这个菜单队列只进行头尾的插入和删除,那么肯定是使用链表效率更高.")])])]),t._v(" "),a("li",[t._v("2.3 我们来做一个思考实验。假设Facebook记录一系列用户名，每当有用户试图登录Facebook时，都查找其用户名，如果找到就允许用户登录。由于经常有用户登录Facebook，因此需要执行大量的用户名查找操作。假设Facebook使用二分查找算法，而这种算法要求能够随机访问——立即获取中间的用户名。考虑到这一点，应使用数组还是链表来存储用户名呢？\n"),a("ul",[a("li",[t._v("随机访问肯定是使用数组更好.")])])]),t._v(" "),a("li",[t._v("2.4 经常有用户在Facebook注册。假设你已决定使用数组来存储用户名，在插入方面数组有何缺点呢？具体地说，在数组中添加新用户将出现什么情况？\n"),a("ul",[a("li",[t._v("插入速度慢,插入后所有后边的元素都要后移,甚至位置不够时需要整个数组复制到内存其他位置.")])])]),t._v(" "),a("li",[t._v("2.5 实际上，Facebook存储用户信息时使用的既不是数组也不是链表。假设Facebook使用的是一种混合数据：链表数组。这个数组包含26个元素，每个元素都指向一个链表。例如，该数组的第一个元素指向的链表包含所有以A打头的用户名，第二个元素指向的链表包含所有以B打头的用户名，以此类推。假设Adit B在Facebook注册，而你需要将其加入前述数据结构中。因此，你访问数组的第一个元素，再访问该元素指向的链表，并将Adit B添加到这个链表末尾。现在假设你要查找Zakhir H。因此你访问第26个元素，再在它指向的链表（该链表包含所有以z打头的用户名）中查找Zakhir H。请问，相比于数组和链表，这种混合数据结构的查找和插入速度更慢还是更快？你不必给出大O运行时间，只需指出这种新数据结构的查找和插入速度更快还是更慢。\n"),a("ul",[a("li",[t._v("相比于数组来说,数组链表的查找肯定是更慢一些,但是插入更快")]),t._v(" "),a("li",[t._v("相比于链表,数组链表的查找要快,插入也会快,因为插入就是先查找再插入,查找省了时间,插入时间都一样,那总的来说插入的也就更快了.")])])])]),t._v(" "),a("h3",{attrs:{id:"选择排序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#选择排序"}},[t._v("#")]),t._v(" 选择排序")]),t._v(" "),a("ul",[a("li",[t._v("假设你电脑上存储了很多乐曲,每个乐队你都记录了被播放次数")]),t._v(" "),a("li",[t._v("需要把这个列表从多到少排序,得到最喜欢的乐队排序")]),t._v(" "),a("li",[t._v("一种方法是遍历这个列表,找出播放次数最多的乐队,然后添加到新列表中,依次这样操作找出第二第三多播放次数的乐队,最终得到一个有序列表")]),t._v(" "),a("li",[t._v("要找出播放次数最多的乐队必须检查列表每个元素,需要时间O(n),对于这种操作需要执行n次.")]),t._v(" "),a("li",[t._v("所以需要总时间O(n²)")])]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("需要检查的元素数越来越少")])]),t._v(" "),a("ul",[a("li",[a("p",[t._v("随着排序的进行，每次需要检查的元素数在逐渐减少，最后一次需要检查的元素都只有一个。既然如此，运行时间怎么还是"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v("2)呢？这个问题问得好，这与大O表示法中的常数相关。第4章将详细解释，这里只简单地说一说。")])]),t._v(" "),a("li",[a("p",[t._v("你说得没错，并非每次都需要检查"),a("em",[t._v("n")]),t._v("个元素。第一次需要检查"),a("em",[t._v("n")]),t._v("个元素，但随后检查的元素数依次为"),a("em",[t._v("n")]),t._v("  1, "),a("em",[t._v("n")]),t._v(" – 2, …, 2和1。平均每次检查的元素数为1/2 × "),a("em",[t._v("n")]),t._v("，因此运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" × 1/2 × "),a("em",[t._v("n")]),t._v(")。但"),a("strong",[t._v("大O表示法省略诸如1/2这样的常数")]),t._v("（有关这方面的完整讨论，请参阅第4章），因此简单地写作"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" × "),a("em",[t._v("n")]),t._v(")或"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v("2)。")])])])]),t._v(" "),a("h3",{attrs:{id:"小结-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-2"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("计算机内存犹如一大堆抽屉。")]),t._v(" "),a("li",[t._v("需要存储多个元素时，可使用数组或链表。")]),t._v(" "),a("li",[t._v("数组的元素都在一起。")]),t._v(" "),a("li",[t._v("链表的元素是分开的，其中每个元素都存储了下一个元素的地址。")]),t._v(" "),a("li",[t._v("数组的读取速度很快。")]),t._v(" "),a("li",[t._v("链表的插入和删除速度很快。")]),t._v(" "),a("li",[t._v("在同一个数组中，所有元素的类型都必须相同（都为int、double等）。")])]),t._v(" "),a("h2",{attrs:{id:"第三章-递归"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第三章-递归"}},[t._v("#")]),t._v(" 第三章:递归")]),t._v(" "),a("h3",{attrs:{id:"递归"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#递归"}},[t._v("#")]),t._v(" 递归")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("假设我们要打开一个带锁的箱子.")])]),t._v(" "),a("li",[a("p",[t._v("这时有一个大箱子里面装着很多小箱子,当然都是纸箱,手就可以打开,小巷子里面还有可能是箱子,而打开带锁箱子的钥匙就在其中")])]),t._v(" "),a("li",[a("p",[t._v("现在有两种找到钥匙的算法")])]),t._v(" "),a("li",[a("p",[t._v("第一种:")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("(1) 创建一个要查找的盒子堆。")]),t._v(" "),a("p",[t._v("(2) 从盒子堆取出一个盒子，在里面找。")]),t._v(" "),a("p",[t._v("(3) 如果找到的是盒子，就将其加入盒子堆中，以便以后再查找。")]),t._v(" "),a("p",[t._v("(4) 如果找到钥匙，则大功告成！")]),t._v(" "),a("p",[t._v("(5) 回到第二步。")])])])]),t._v(" "),a("li",[a("p",[t._v("第二种:")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("(1) 检查盒子中的每样东西。")]),t._v(" "),a("p",[t._v("(2) 如果是盒子，就回到第一步。")]),t._v(" "),a("p",[t._v("(3) 如果是钥匙，就大功告成！")])])])]),t._v(" "),a("li",[a("p",[t._v("第一种就是while循环,只要盒子堆不空就从中取出一个盒子打开检查")])]),t._v(" "),a("li",[a("p",[t._v("第二种是递归,自己调用自己,"),a("code",[t._v("打开盒子")]),t._v("->发现盒子后再次"),a("code",[t._v("打开盒子")])])]),t._v(" "),a("li",[a("p",[t._v("两种方法作用相同,如果使用"),a("strong",[t._v("循环")]),t._v("程序"),a("strong",[t._v("性能可能更高")]),t._v(",使用"),a("strong",[t._v("递归")]),t._v("程序"),a("strong",[t._v("可能更容易理解")])])])]),t._v(" "),a("h3",{attrs:{id:"基线条件和递归条件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基线条件和递归条件"}},[t._v("#")]),t._v(" 基线条件和递归条件")]),t._v(" "),a("ul",[a("li",[t._v("假设我们写一个倒计时的递归函数,我们预想的是从3-0,到了0就停止")]),t._v(" "),a("li",[t._v("但是可能它会无限循环下去,0,-1,-2....")]),t._v(" "),a("li",[t._v("这时候就需要告诉它何时停止递归.")]),t._v(" "),a("li",[t._v("每个递归函数都有两部分：基线条件（base case）和递归条件（recursive case）。"),a("strong",[t._v("递归条件")]),t._v("指的是"),a("strong",[t._v("函数调用自己")]),t._v("，而"),a("strong",[t._v("基线条件")]),t._v("则指的是"),a("strong",[t._v("函数不再调用自己")]),t._v("，从而"),a("strong",[t._v("避免形成无限循环")]),t._v("。")]),t._v(" "),a("li",[t._v("在这个例子里,基线条件就是判断如果时间小于等于0,递归条件就是调用自己,参数中的数字减一.")])]),t._v(" "),a("h3",{attrs:{id:"栈"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#栈"}},[t._v("#")]),t._v(" 栈")]),t._v(" "),a("ul",[a("li",[t._v("假设你去野外烧烤，并为此创建了一个待办事项清单——一叠便条。")]),t._v(" "),a("li",[t._v("一叠便条比之前的数组和链表那里的手写在一张纸上的待办事项要简单的多")]),t._v(" "),a("li",[t._v("最新的待办事项贴在便条的最上方,读取待办事项只需要把最上方的那张表调阅读再删除即可.")]),t._v(" "),a("li",[t._v("这种只有两种操作压入（插入）和弹出（删除并读取）的数据结构就成为栈.先进后出.")])]),t._v(" "),a("h3",{attrs:{id:"调用栈"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#调用栈"}},[t._v("#")]),t._v(" 调用栈")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("计算机在内部使用被称为"),a("code",[t._v("调用栈")]),t._v("的栈.")])]),t._v(" "),a("li",[a("p",[t._v("假如你现在要执行一个函数greet")])]),t._v(" "),a("li",[a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("greet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hello, "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"!"')]),t._v(" \n\n    greet2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"getting ready to say bye..."')]),t._v(" \n\n    bye"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("p",[t._v("这个函数问候用户，再调用另外两个函数。这两个函数的代码如下。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("greet2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"how are you, "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"?"')]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("bye")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ok bye!"')]),t._v(" \n")])])])]),t._v(" "),a("li",[a("p",[t._v("调用"),a("code",[t._v('greet("jack")')]),t._v("时计算机为该函数分配一块内存.("),a("strong",[t._v("其实这就是调用栈的一部分")]),t._v(")")])]),t._v(" "),a("li",[a("p",[t._v("内存中第一个属于greet的位置,变量name被设置为jack")])]),t._v(" "),a("li",[a("p",[t._v("接下来打印"),a("code",[t._v("hello,jack")]),t._v(",再调用"),a("code",[t._v("greet2(jack)")]),t._v(",同样计算机也为这个函数分配一块内存")])]),t._v(" "),a("li",[a("p",[t._v("计算机使用一个栈("),a("strong",[t._v("就是调用栈")]),t._v(")来表示这些内存块("),a("strong",[t._v("所有内存块都被装在这个调用栈")]),t._v("),第二个内存块在第一个内存块上面.")])]),t._v(" "),a("li",[a("p",[t._v("打印"),a("code",[t._v("how are you,jack?")]),t._v("然后从函数调用调用返回,此时栈顶属于greet2的内存块被弹出.")])]),t._v(" "),a("li",[a("p",[t._v("这个时候栈内只有greet的内存块,栈顶的内存块也就是greet的了,调用完greet2时,greet值执行了一部分:"),a("strong",[t._v("调用另一个函数时，当前函数暂停并处于未完成状态。")])])]),t._v(" "),a("li",[a("p",[t._v("执行完greet2回到greet,从离开的地方往下执行,首先打印"),a("code",[t._v("getting ready to say bye…")]),t._v(",再调用函数bye")])]),t._v(" "),a("li",[a("p",[t._v("栈顶就会添加函数bye的内存块,然后打印"),a("code",[t._v("ok,bye!")]),t._v(",并从这个函数返回")])]),t._v(" "),a("li",[a("p",[t._v("然后又回到了greet,再没有别的操作了,就从greet返回")])])]),t._v(" "),a("h3",{attrs:{id:"递归调用栈"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#递归调用栈"}},[t._v("#")]),t._v(" 递归调用栈")]),t._v(" "),a("ul",[a("li",[a("p",[a("strong",[t._v("递归函数也使用调用栈")])])]),t._v(" "),a("li",[a("p",[t._v("每次递归调用时,递归函数都有自己那个相同的变量,在"),a("strong",[t._v("同一个函数的一次递归调用中不能访问另一次递归调用的相同变量值.")])])]),t._v(" "),a("li",[a("p",[t._v("之前有两种寻找钥匙的方法,现在还有种新的方法")])]),t._v(" "),a("li",[a("p",[t._v("使用循环方法时,始终知道还有哪些盒子需要查找,但是使用递归方法时没有盒子堆,算法怎么知道还有哪些盒子需要查找呢??")])]),t._v(" "),a("li",[a("p",[t._v("通俗点说就是第一级别的盒子只打开了第一个,就开始打开其中第二级别的盒子,第一级别的其他盒子都没动,那"),a("strong",[t._v("怎么保证最后还能记得哪些盒子没动过")]),t._v("呢?")])]),t._v(" "),a("li",[a("p",[t._v("原来“盒子堆”存储在了栈中！这个栈包含未完成的函数调用，每个函数调用都包含还未检")]),t._v(" "),a("p",[t._v("查完的盒子。使用"),a("strong",[t._v("栈很方便")]),t._v("，因为你"),a("strong",[t._v("无需自己跟踪盒子堆")]),t._v("——"),a("strong",[t._v("栈替你这样做")]),t._v("了。")])]),t._v(" "),a("li",[a("p",[t._v("也就是打开第一个第一级别盒子的时候,入栈的信息里包含了其它没打开的第一级别的盒子,等第一个第一级别盒子里的所有盒子都开完了,可以从"),a("strong",[t._v("最底层")]),t._v("的也就是"),a("strong",[t._v("最开始入栈的最大的盒子")]),t._v("入栈的信息里"),a("strong",[t._v("取出其它第一级别盒子信息压入栈中")]),t._v("继续往里开.")])]),t._v(" "),a("li",[a("p",[t._v("使用栈虽然很方便，但是也要付出代价：存储详尽的信息可能占用大量的内存。每个函数调用都要占用一定的内存，如果栈很高，就意味着计算机存储了大量函数调用的信息。在这种情况下，你有两种选择。")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("重新编写代码，转而使用循环。")])]),t._v(" "),a("li",[a("p",[t._v("使用尾递归。这是一个高级递归主题，不在本书的讨论范围内。另外，并非所有的语言")]),t._v(" "),a("p",[t._v("都支持尾递归。")])])])])]),t._v(" "),a("h3",{attrs:{id:"小结-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-3"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("递归指的是调用自己的函数。")]),t._v(" "),a("li",[t._v("每个递归函数都有两个条件：基线条件和递归条件。")]),t._v(" "),a("li",[t._v("栈有两种操作：压入和弹出。")]),t._v(" "),a("li",[t._v("所有函数调用都进入调用栈。")]),t._v(" "),a("li",[t._v("调用栈可能很长，这将占用大量的内存。")])]),t._v(" "),a("h2",{attrs:{id:"第四章-快速排序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第四章-快速排序"}},[t._v("#")]),t._v(" 第四章:快速排序")]),t._v(" "),a("h3",{attrs:{id:"分而治之"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分而治之"}},[t._v("#")]),t._v(" 分而治之")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("分而治之")]),t._v("（divide and conquer，"),a("strong",[t._v("D&C")]),t._v("）——一种著名的"),a("strong",[t._v("递归式问题解决方法")]),t._v("。")]),t._v(" "),a("li",[t._v("如何将一块土地均匀分成方块并保证分出方块最大呢?使用D&C策略,该算法是递归的,使用它解决问题的过程包括"),a("strong",[t._v("两个步骤")]),t._v(".\n"),a("ul",[a("li",[t._v("(1) "),a("strong",[t._v("找出基线条件，这种条件必须尽可能简单")]),t._v("。")]),t._v(" "),a("li",[t._v("(2) "),a("strong",[t._v("不断将问题分解（或者说缩小规模），直到符合基线条件")]),t._v("。")])])]),t._v(" "),a("li",[t._v("现在需要找出递归条件，这正是D&C的用武之地。根据D&C的定义，"),a("strong",[t._v("每次递归调用都必须缩小问题的规模")]),t._v("。如何缩小前述问题的规模呢？我们首先找出这块地可容纳的最大方块。")]),t._v(" "),a("li",[t._v("这块地长1680m,宽640m,最大划出的方块就是640x640大小的,可以划出两块,剩下一小块地.这下你应该灵光乍现,为什么不对剩下的小块地使用相同算法??")]),t._v(" "),a("li",[t._v("现在剩余的地为640x400,"),a("strong",[t._v("欧几里得算法")]),t._v("告诉我们,适用于这小块地的最大方块，也是适用于整块地的最大方块。")]),t._v(" "),a("li",[t._v("再次划分,最大方块为400x400,剩余的地为400x240,再从这块地划出最大方块,余下的地为240x160.")]),t._v(" "),a("li",[t._v("继续划分,划分出160x160,剩余160x80,因为160是80的整数倍,这小块土地一分为二后不会剩下任何土地,所以对最开始的那块地,可以划分出来的最大方块为80x80")])]),t._v(" "),a("hr"),t._v(" "),a("ul",[a("li",[t._v("再看个例子,给定一个数字数组,把数字相加返回结果.")]),t._v(" "),a("li",[t._v("使用循环解决是很简单的,但是如何使用递归解决呢")]),t._v(" "),a("li",[a("strong",[t._v("第一步")]),t._v(":首先找出基线条件,一般和数组相关的基线条件就是数组不包含任何元素或只包含一个元素.")]),t._v(" "),a("li",[a("strong",[t._v("第二步")]),t._v(":每次递归都要离空数组更近一步")]),t._v(" "),a("li",[t._v("函数sum的工作原理类似于接受一个列表,如果列表为空就返回0,否则计算列表中除第一个数字外其他数字的总和再与第一个数字相加返回结果")]),t._v(" "),a("li",[t._v("这样就变成了x1+[剩余元素]->x1+x2+[剩余元素]->....")]),t._v(" "),a("li",[t._v("因为"),a("strong",[t._v("递归保存了未完成的函数调用的状态")]),t._v(",所以x1+x2这些数的和会被保留,最后全部相加")]),t._v(" "),a("li",[a("strong",[t._v("编写涉及数组的递归函数时，基线条件通常是数组为空或只包含一个元素。陷入困境时，请检查基线条件是不是这样的。")])])]),t._v(" "),a("h4",{attrs:{id:"练习-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-2"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("p",[t._v("4.1 请编写前述sum函数的代码。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//基线条件")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("4.2 编写一个递归函数来计算列表包含的元素数。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTotal")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//基线条件")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//递归条件")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("remove")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getTotal")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("4.3 找出列表中最大的数字。")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getMax")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" max"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//基线条件")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" max"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//递归条件")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getMax")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("4.4 还记得第1章介绍的二分查找吗？它也是一种分而治之算法。你能找出二分查找算法的基线条件和递归条件吗？")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("binarySearch")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("equals")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        end "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("binarySearch")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("subList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("end"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("h3",{attrs:{id:"快速排序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#快速排序"}},[t._v("#")]),t._v(" 快速排序")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("快速排序")]),t._v("是一种"),a("strong",[t._v("常用")]),t._v("的排序算法，"),a("strong",[t._v("比选择排序快得多")]),t._v("。例如，C语言标准库中的函数qsort实现的就是快速排序。快速排序"),a("strong",[t._v("也使用了D&C")]),t._v("。")]),t._v(" "),a("li",[t._v("快速排序也遵守数组的规律,基线条件为数组为空或只包含一个元素,这种情况下,只需原样返回数组,根本就不用排序.")]),t._v(" "),a("li",[t._v("对两个元素的数组排序很容易,检查第一个元素是否比第二个小,如果不就交换它们的位置.")]),t._v(" "),a("li",[t._v("要使用D&C,因此要将数组分解,直到满足基线条件,首先,从数组中选择一个元素,称为"),a("strong",[t._v("基准值(")]),a("code",[t._v("pivot")]),t._v(").暂时将第一个元素用作基准值.")]),t._v(" "),a("li",[t._v("接下来"),a("strong",[t._v("找出比基准值小的元素以及比基准值大的元素")]),t._v(",这被称为"),a("strong",[t._v("分区")]),t._v(".")]),t._v(" "),a("li",[t._v("现在就有了\n"),a("ul",[a("li",[t._v("一个由所有小于基准值的数组组成的子数组.")]),t._v(" "),a("li",[t._v("基准值")]),t._v(" "),a("li",[t._v("一个由所有大于基准值的数组组成的子数组.")])])]),t._v(" "),a("li",[t._v("只是进行分区,得到的子数组是无序的,如果是有序的排序将非常容易.左边的数组+[基准值]+右边的数组即可.")]),t._v(" "),a("li",[t._v("如何对子数组排序呢?对两个元素的数组以及空数组,快排知道如何排序,因此只要对这两个子数组进行快速排序,合并结果,就能得到一个有序数组.")]),t._v(" "),a("li",[t._v("刚才你大致见识了归纳证明！"),a("strong",[t._v("归纳证明")]),t._v("是一种证明算法行之有效的方式，它分两步：基线条件和归纳条件。")]),t._v(" "),a("li",[t._v("对于快速排序，可使用类似的推理。在基线条件中，我证明这种算法对空数组或包含一个元素的数组管用。在归纳条件中，我证明如果快速排序对包含一个元素的数组管用，对包含两个元素的数组也将管用；如果它对包含两个元素的数组管用，对包含三个元素的数组也将管用，以此类推。因此，我可以说，快速排序对任何长度的数组都管用。这里不再深入讨论归纳证明，但它很有趣，并与D&C协同发挥作用。")])]),t._v(" "),a("h3",{attrs:{id:"再谈大o表示法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#再谈大o表示法"}},[t._v("#")]),t._v(" 再谈大O表示法")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("还有一种名为合并排序（merge sort）的排序算法，其运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")，比选择排序快得多！快速排序的情况比较棘手，在最糟情况下，其运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v("2)。")])]),t._v(" "),a("li",[a("p",[t._v("与选择排序一样慢！但这是最糟情况。在平均情况下，快速排序的运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")。你可能会有如下疑问。")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("这里说的"),a("strong",[t._v("最糟情况")]),t._v("和"),a("strong",[t._v("平均情况")]),t._v("是什么意思呢？")])]),t._v(" "),a("li",[a("p",[t._v("若快速排序在平均情况下的运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")，而合并排序的运行时间总是"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")，"),a("strong",[t._v("为何不使用合并排序")]),t._v("？它不是更快吗？")])])])])]),t._v(" "),a("h4",{attrs:{id:"比较合并排序和快速排序"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#比较合并排序和快速排序"}},[t._v("#")]),t._v(" 比较合并排序和快速排序")]),t._v(" "),a("ul",[a("li",[t._v("假如有一个算法是遍历打印列表元素,还有一个算法和它一样但是每次打印前暂停一秒.")]),t._v(" "),a("li",[t._v("这两个函数都迭代列表一次,运行时间都为O(n),但是明显第一个函数要快的多,因为没有暂停,因此虽然大O表示法这两个函数速度相同,实际上第一个更快.")]),t._v(" "),a("li",[t._v("大I表示法O(n)中,n实际上指的是这样:c*n")]),t._v(" "),a("li",[t._v("c是算法所需的固定时间量,被称为常量,例如第一个函数所需时间可能是"),a("code",[t._v("10毫秒*n")]),t._v(",第二个是"),a("code",[t._v("1秒*n")]),t._v(".")]),t._v(" "),a("li",[a("strong",[t._v("通常不考虑常量")]),t._v(",因为如果大O运行时间不同,这些常量会无关紧要.")]),t._v(" "),a("li",[t._v("但"),a("strong",[t._v("有时候，常量的影响可能很大")]),t._v("，对快速查找和合并查找来说就是如此。"),a("strong",[t._v("快速查找的常量比合并查找小")]),t._v("，因此"),a("strong",[t._v("如果它们的运行时间都为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")，快速查找的速度将更快")]),t._v("。实际上，快速查找的速度确实更快，因为相对于遇上最糟情况，它"),a("strong",[t._v("遇上平均情况的可能性要大得多")]),t._v("。")]),t._v(" "),a("li",[t._v("何为平均情况，何为最糟情况呢？")])]),t._v(" "),a("h4",{attrs:{id:"平均情况和最糟情况"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#平均情况和最糟情况"}},[t._v("#")]),t._v(" 平均情况和最糟情况")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("快排性能高度依赖于你选择的基准值,假设你"),a("strong",[t._v("总将第一个元素用作基准值")]),t._v(",且要处理的数组是有序的,由于快排算法不检查输入数组是否有序,因此它依然尝试对其进行排序.")])]),t._v(" "),a("li",[a("p",[t._v("这样数组并没有被分成两半,相反其中一个子数组始终为空,这"),a("strong",[t._v("导致调用栈非常长")]),t._v(".")])]),t._v(" "),a("li",[a("p",[t._v("现在假设"),a("strong",[t._v("总是将中间元素用作基准值")]),t._v(",这种情况下调用栈短得多,因为每次分成两半,所以不需要那么多递归调用,很快就到达了基线条件,因此"),a("strong",[t._v("调用栈短得多")]),t._v(".")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("第一个例子")]),t._v("是"),a("strong",[t._v("最糟情况")]),t._v(","),a("strong",[t._v("第二个例子")]),t._v("是"),a("strong",[t._v("最佳情况")]),t._v(",在"),a("strong",[t._v("最糟")]),t._v("情况下，栈长为"),a("strong",[a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")")]),t._v("，而在"),a("strong",[t._v("最佳情")]),t._v("况下，栈长为"),a("strong",[a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(")")]),t._v("。")])]),t._v(" "),a("li",[a("p",[t._v("你将一个元素用作基准值，并将其他的元素划分到两个子数组中。这涉及数组中的全部8个元素，因此该操作的时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")。在调用栈的第一层，涉及全部8个元素，但实际上，在调用栈的"),a("strong",[t._v("每层都涉及"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")个元素")]),t._v("。")])]),t._v(" "),a("li",[a("p",[t._v("即便以不同的方式划分数组，每次也将涉及"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")个元素。"),a("strong",[t._v("!!!这里注意,处理8个元素也是n,处理3个元素也是n,n只是一个可变量,即使随着递归一层层深入处理的元素会越来越少,但是始终都是要处理的所有元素,也就是n.")])])]),t._v(" "),a("li",[a("p",[t._v("因此，完成每层所需的时间都为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")。")])]),t._v(" "),a("li",[a("p",[t._v("在这个示例中，"),a("strong",[t._v("层数为"),a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(")")]),t._v("（用技术术语说，调用栈的高度为"),a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(")），而每层需要的时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")。因此整个算法需要的时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(") * "),a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(") = "),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")。这就是最佳情况。")])]),t._v(" "),a("li",[a("p",[t._v("这里要告诉你的是，"),a("strong",[t._v("最佳情况也是平均情况")]),t._v("。只要你每次都随机地选择一个数组元素作为基准值，快速排序的平均运行时间就将为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")。快速排序是最快的排序算法之一，也是D&C典范。")])])]),t._v(" "),a("h4",{attrs:{id:"练习-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-3"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("使用大O表示法时，下面各种操作都需要多长时间？")])]),t._v(" "),a("li",[a("p",[t._v("4.5 打印数组中每个元素的值。答:O(n)")])]),t._v(" "),a("li",[a("p",[t._v("4.6 将数组中每个元素的值都乘以2。答:O(n)")])]),t._v(" "),a("li",[a("p",[t._v("4.7 只将数组中第一个元素的值乘以2。答:O(1)")])]),t._v(" "),a("li",[a("p",[t._v("4.8 根据数组包含的元素创建一个乘法表，即如果数组为[2, 3, 7, 8, 10]，首先将每个元素都乘以2，再将每个元素都乘以3，然后将每个元素都乘以7，以此类推。答:O(n²)")])])]),t._v(" "),a("h3",{attrs:{id:"小结-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-4"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("D&C将问题逐步分解。使用D&C处理列表时，基线条件很可能是空数组或只包含一个元")])]),t._v(" "),a("p",[t._v("素的数组。")]),t._v(" "),a("ul",[a("li",[t._v("实现快速排序时，请随机地选择用作基准值的元素。快速排序的平均运行时间为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(" log "),a("em",[t._v("n")]),t._v(")。")]),t._v(" "),a("li",[t._v("大O表示法中的常量有时候事关重大，这就是快速排序比合并排序快的原因所在。")]),t._v(" "),a("li",[t._v("比较简单查找和二分查找时，常量几乎无关紧要，因为列表很长时，"),a("em",[t._v("O")]),t._v("(log "),a("em",[t._v("n")]),t._v(")的速度比"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")]),t._v(")快得多。")])]),t._v(" "),a("h2",{attrs:{id:"第五章-散列表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第五章-散列表"}},[t._v("#")]),t._v(" 第五章:散列表")]),t._v(" "),a("ul",[a("li",[t._v("假如你在杂货铺上班,有人来买东西,你要在本子上查价格.")]),t._v(" "),a("li",[t._v("如果本子不是按字母排序,查找苹果价格就需要浏览每一行,也就是第一章的简单查找,需要O(n)的时间.")]),t._v(" "),a("li",[t._v("如果本子按字母排序,可用二分查找发,需要O(logn)的时间")]),t._v(" "),a("li",[t._v("二分查找很快,但是作为收银员在本子里找价格很痛苦,需要一名记住所有价格的人--小红,问她就可得到答案,不管商品有多少,报价时间都为O(1),比二分查找还快.")]),t._v(" "),a("li",[t._v("从数据结构来看,可以用数组记录")]),t._v(" "),a("li",[a("code",[t._v("[(apple,1.66),(mile,1.49)]")])]),t._v(" "),a("li",[t._v("数组的每个元素包含两个内容,商品名和价格,如果按商品名排序,可以用二分查找寻找商品价格,时间将为O(logn).")]),t._v(" "),a("li",[t._v("但是"),a("strong",[t._v("你希望时间为O(1),这就是散列函数的用武之地")])])]),t._v(" "),a("h3",{attrs:{id:"散列函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#散列函数"}},[t._v("#")]),t._v(" 散列函数")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("散列函数")]),t._v("无论你"),a("strong",[t._v("给他什么数据")]),t._v(",他都"),a("strong",[t._v("还你一个数字")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("它必须是一致的")]),t._v(",假如你输入apple得到的是4,每次输入apple都必须为4,也就是"),a("strong",[t._v("每次输入同一个数得到的反馈数字都始终如一")])]),t._v(" "),a("li",[a("strong",[t._v("它应将不同的输入映射到不同的数字")]),t._v("。如果一个散列函数不管输入是什么都返回1，它就不是好的散列函数。"),a("strong",[t._v("最理想的情况是，将不同的输入映射到不同的数字。")])])])]),t._v(" "),a("li",[t._v('这样我们就可以打造自己的"小红":\n'),a("ul",[a("li",[t._v("首先创建一个空数组,在数组中将存储价格.")]),t._v(" "),a("li",[t._v("输入apple到三列数组,输入为3,就把苹果价格存储到数组索引3处")]),t._v(" "),a("li",[t._v("不断重复最终将数组填满价格")]),t._v(" "),a("li",[t._v("现在需要知道apple价格,无需在数组中查找,只需apple作为输入交给散列函数,他告诉你在索引3处,果然可以找到对应价格")]),t._v(" "),a("li",[t._v("散列函数总是将同样的输入映射到相同的索引。")]),t._v(" "),a("li",[t._v("散列函数将不同的输入映射到不同的索引。")]),t._v(" "),a("li",[a("strong",[t._v("散列函数知道数组有多大，只返回有效的索引")]),t._v("。如果数组"),a("strong",[t._v("包含5个元素")]),t._v("，散列函数"),a("strong",[t._v("就不会返回无效索引100")]),t._v("。")])])]),t._v(" "),a("li",[t._v("这样"),a("strong",[t._v("结合")]),t._v("使用"),a("strong",[t._v("散列函数")]),t._v("和"),a("strong",[t._v("数组")]),t._v("创建了一种被称为"),a("strong",[t._v("散列表")]),t._v("（hash table）的数据结构。第一种"),a("strong",[t._v("包含额外逻辑")]),t._v("的数据结构。也被称为散列映射、映射、字典和关联数组。")]),t._v(" "),a("li",[t._v("散列表的"),a("strong",[t._v("速度很快")]),t._v("！散列表也使用数组来存储数据，因此其获取元素的速度与数组一样快。")]),t._v(" "),a("li",[t._v("根本"),a("strong",[t._v("不需要自己去实现")]),t._v("散列表，任一优秀的语言都提供了散列表实现。")])]),t._v(" "),a("h4",{attrs:{id:"练习-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-4"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("p",[t._v("对于同样的输入，散列表必须返回同样的输出，这一点很重要。如果不是这样的，就无法找到你在散列表中添加的元素！")]),t._v(" "),a("p",[t._v("请问下面哪些散列函数是"),a("strong",[t._v("一致")]),t._v("的？(这里的一致指的是"),a("code",[t._v("它必须是一致的,假如你输入apple得到的是4,每次输入apple都必须为4")]),t._v(")")]),t._v(" "),a("p",[t._v("5.1 f(x) = 1 <--- 无论输入是什么，都返回1       一致")]),t._v(" "),a("p",[t._v("5.2  f(x) = rand() <---每次都返回一个随机数    不 一致")]),t._v(" "),a("p",[t._v("5.3 f(x) = next_empty_slot() <---返回散列表中下一个空位置的索引    不 一致")]),t._v(" "),a("p",[t._v("5.4 f(x) = len(x) <---将字符串的长度用作索引     一致")]),t._v(" "),a("h3",{attrs:{id:"应用案例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#应用案例"}},[t._v("#")]),t._v(" 应用案例")]),t._v(" "),a("h4",{attrs:{id:"将散列表用于查找"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将散列表用于查找"}},[t._v("#")]),t._v(" 将散列表用于查找")]),t._v(" "),a("ul",[a("li",[t._v("假设要创建一个电话簿,将姓名映射到电话号\n"),a("ul",[a("li",[t._v("添加联系人和电话号码")]),t._v(" "),a("li",[t._v("通过输入联系人获取电话号码")])])]),t._v(" "),a("li",[t._v("这就非常适合使用散列表,在"),a("strong",[t._v("以下情况适合使用散列表")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("创建映射")])]),t._v(" "),a("li",[a("strong",[t._v("查找")])])])]),t._v(" "),a("li",[t._v("无论访问哪个网站网址都必须转换为IP地址,这个过程被称为"),a("code",[t._v("DNS解析")]),t._v(",散列表是提供这种功能的方式之一")])]),t._v(" "),a("h4",{attrs:{id:"防止重复"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#防止重复"}},[t._v("#")]),t._v(" 防止重复")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("建设你负责一个投票站,每人只能投一票,如何避免重复投票")])]),t._v(" "),a("li",[a("p",[t._v("有人投票时你问他的全名,和投票者名单对比,如果在名单中说明投过了,否则就把名字加入名单中让他投票.")])]),t._v(" "),a("li",[a("p",[t._v("名单很长,就很麻烦,更好的方法是使用散列表")])]),t._v(" "),a("li",[a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("vote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"张三"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("vote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"李四"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("vote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"王老五"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("vote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"张三"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("vote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"王老五"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("vote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("contains")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"已经投过票了"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"恭喜你投票成功"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        set"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])]),t._v(" "),a("h4",{attrs:{id:"将散列表用于缓存"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将散列表用于缓存"}},[t._v("#")]),t._v(" 将散列表用于缓存")]),t._v(" "),a("ul",[a("li",[t._v("假如你的侄女没完的问你关于星球的问题,每次你都得搜索再告诉她,这需要几分钟,假如她老问你月球离地球多远,很快你记住了238900英里,不用再去搜索直接告诉她答案,这就是缓存的工作原理:网站将数据记住,而不再重新计算.")]),t._v(" "),a("li",[t._v("你打开斗鱼,如果没有登录看到的将是登录页面,每个人看到的登录页面都一样,斗鱼被反复要求在用户注销时显示主页,所以斗鱼就不让服务器生成主页,而是保存主页,有需要时直接发给用户")]),t._v(" "),a("li",[t._v("这就是缓存,有两个优点\n"),a("ul",[a("li",[t._v("用户能更快的看到网页")]),t._v(" "),a("li",[t._v("斗鱼需要做的工作更少")])])]),t._v(" "),a("li",[t._v("所有大型网站都使用缓存,而"),a("strong",[t._v("缓存的数据则存储在散列表中")])])]),t._v(" "),a("h4",{attrs:{id:"小结-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-5"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("这里总结一下，散列表适合用于：\n"),a("ul",[a("li",[t._v("模拟映射关系；")]),t._v(" "),a("li",[t._v("防止重复；")]),t._v(" "),a("li",[t._v("缓存/记住数据，以免服务器再通过处理来生成它们。")])])])]),t._v(" "),a("h3",{attrs:{id:"冲突"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#冲突"}},[t._v("#")]),t._v(" 冲突")]),t._v(" "),a("ul",[a("li",[t._v("要明白散列表的"),a("strong",[t._v("性能")]),t._v("，你得先"),a("strong",[t._v("搞清楚什么是冲突")]),t._v("。")]),t._v(" "),a("li",[t._v("之前告诉你的是，散列函数总是将不同的键映射到数组的不同位置.实际上，几乎不可能编写出这样的散列函数。")]),t._v(" "),a("li",[t._v("假设你有一个数组,输入apple存储在第一个位置,输入avocados分配给你的又是第一个位置,这种情况被称为冲突:"),a("strong",[t._v("给两个键分配的位置相同")])]),t._v(" "),a("li",[a("strong",[t._v("处理冲突")]),t._v("的方式很多，"),a("strong",[t._v("最简单")]),t._v("的办法如下：如果两个键映射到了同一个位置，就"),a("strong",[t._v("在这个位置存储一个链表")]),t._v("。")]),t._v(" "),a("li",[t._v("如果这个链表很短，也没什么大不了——只需搜索三四个元素。")]),t._v(" "),a("li",[t._v("如果除第一个位置外，整个散列表都是空的，而第一个位置包含一个很长的列表！这与一开始就将所有元素存储到一个链表中一样糟糕：散列表的速度会很慢")]),t._v(" "),a("li",[t._v("散列函数很重要，好的散列函数很少导致冲突。")])]),t._v(" "),a("h3",{attrs:{id:"性能"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#性能"}},[t._v("#")]),t._v(" 性能")]),t._v(" "),a("ul",[a("li",[t._v("在"),a("strong",[t._v("平均情况")]),t._v("下，"),a("strong",[t._v("散列表执行各种操作的时间都为"),a("em",[t._v("O")]),t._v("(1)")]),t._v("。"),a("em",[t._v("O")]),t._v("(1)被称为"),a("strong",[t._v("常量时间")]),t._v("。你以前没有见过常量时间，它并不意味着马上，而是说"),a("strong",[t._v("不管散列表多大，所需的时间都相同。")])]),t._v(" "),a("li",[a("strong",[t._v("无论散列表包含一个元素还是10亿个元素，从其中获取数据所需的时间都相同")]),t._v("。实际上，你以前见过常量时间——从数组中获取一个元素所需的时间就是固定的：不管数组多大，从中获取一个元素所需的时间都是相同的。在平均情况下，散列表的速度确实很快")]),t._v(" "),a("li",[t._v("在"),a("strong",[t._v("最糟情况")]),t._v("下，"),a("strong",[t._v("散列表所有操作的运行时间都为"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("n")])]),t._v(")——线性时间，"),a("strong",[t._v("这真的很慢")]),t._v("。")]),t._v(" "),a("li",[t._v("在平均情况下，散列表的查找（获取给定索引处的值）速度与数组一样快，而插入和删除速度与链表一样快，因此它兼具两者的优点！但在最糟情况下，散列表的各种操作的速度都很慢。因此，在使用散列表时，避开最糟情况至关重要。为此，需要避免冲突。而要"),a("strong",[t._v("避免冲突")]),t._v("，需要有：\n"),a("ul",[a("li",[a("strong",[t._v("较低的填装因子")]),t._v("；")]),t._v(" "),a("li",[a("strong",[t._v("良好的散列函数")]),t._v("。")])])])]),t._v(" "),a("h4",{attrs:{id:"填装因子"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#填装因子"}},[t._v("#")]),t._v(" 填装因子")]),t._v(" "),a("ul",[a("li",[t._v("填装因子="),a("strong",[t._v("散列表包含的元素数/位置总数")]),t._v(",五个位置的数组装了三个元素,填装因子就为0.6")]),t._v(" "),a("li",[t._v("填装因子度量的是散列表中有多少位置是空的。")]),t._v(" "),a("li",[t._v("最佳情况下，每个元素都将有自己的位置。这个散列表的填装因子为1。如果这个散列表只有50个位置呢？填充因子将为2。")]),t._v(" "),a("li",[a("strong",[t._v("填装因子大于1意味着商品数量超过了数组的位置数")]),t._v("。一旦填装因子开始增大，你就"),a("strong",[t._v("需要在散列表中添加位置")]),t._v("，这被称为"),a("strong",[t._v("调整长度")]),t._v("（resizing）。\n"),a("ul",[a("li",[t._v("首先创建一个更长的新数组：通常将数组增长一倍。")]),t._v(" "),a("li",[t._v("接下来，你需要使用函数hash将所有的元素都插入到这个新的散列表中。")])])]),t._v(" "),a("li",[t._v("这个新散列表的填装因子比原来低多了！"),a("strong",[t._v("填装因子越低，发生冲突的可能性越小，散列表的性能越高")]),t._v("。一个不错的"),a("strong",[t._v("经验规则")]),t._v("是："),a("strong",[t._v("一旦填装因子大于0.7，就调整散列表的长度。")])]),t._v(" "),a("li",[t._v("调整散列表长度的工作需要很长时间！因此你不会希望频繁地这样做。平均而言，"),a("strong",[t._v("即便考虑到调整长度所需的时间，散列表操作所需的时间也为"),a("em",[t._v("O")]),t._v("(1)")]),t._v("。")])]),t._v(" "),a("h4",{attrs:{id:"良好的散列函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#良好的散列函数"}},[t._v("#")]),t._v(" 良好的散列函数")]),t._v(" "),a("ul",[a("li",[t._v("良好的散列函数让数组中的值呈均匀分布。糟糕的散列函数让值扎堆，导致大量的冲突。不过你根本不用操心什么样的散列函数是好的.")])]),t._v(" "),a("h5",{attrs:{id:"练习-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-5"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("散列函数的结果必须是均匀分布的，这很重要。它们的映射范围必须尽可能大。最糟糕的散")])]),t._v(" "),a("li",[a("p",[t._v("列函数莫过于将所有输入都映射到散列表的同一个位置。")])]),t._v(" "),a("li",[a("p",[t._v("假设你有四个处理字符串的散列函数。")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("A. 不管输入是什么，都返回1。")])]),t._v(" "),a("li",[a("p",[t._v("B. 将字符串的长度用作索引。")])]),t._v(" "),a("li",[a("p",[t._v("C. 将字符串的第一个字符用作索引。即将所有以a打头的字符串都映射到散列表的同一个位置，以此类推。")])]),t._v(" "),a("li",[a("p",[t._v("D. 将每个字符都映射到一个素数：a = 2，b = 3，c = 5，d = 7，e = 11，等等。对于给定的字符串，这个散列函数将其中每个字符对应的素数相加，再计算结果除以散列表长度的余数。")])])])]),t._v(" "),a("li",[a("p",[t._v("例如，如果散列表的长度为10，字符串为bag，则索引为(3 + 2 + 17) % 10 = 22 % 10 = 2。")])]),t._v(" "),a("li",[a("p",[t._v("在下面的每个示例中，上述哪个散列函数可实现均匀分布？假设散列表的长度为10。")])]),t._v(" "),a("li",[a("p",[t._v("5.5 将姓名和电话号码分别作为键和值的电话簿，其中联系人姓名为Esther、Ben、Bob和Dan。")]),t._v(" "),a("ul",[a("li",[t._v("答:D")])])]),t._v(" "),a("li",[a("p",[t._v("5.6 电池尺寸到功率的映射，其中电池尺寸为A、AA、AAA和AAAA。")]),t._v(" "),a("ul",[a("li",[t._v("答:B D")])])]),t._v(" "),a("li",[a("p",[t._v("5.7 书名到作者的映射，其中书名分别为Maus、Fun Home和Watchmen。")]),t._v(" "),a("ul",[a("li",[t._v("答:C B D")])])])]),t._v(" "),a("h3",{attrs:{id:"小结-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-6"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("你几乎根本不用自己去实现散列表，因为你使用的编程语言提供了散列表实现。你可使用Python提供的散列表，并假定能够获得平均情况下的性能：常量时间。")]),t._v(" "),a("li",[t._v("散列表是一种功能强大的数据结构，其操作速度快，还能让你以不同的方式建立数据模型。你可能很快会发现自己经常在使用它。")]),t._v(" "),a("li",[t._v("你可以结合散列函数和数组来创建散列表。")]),t._v(" "),a("li",[t._v("冲突很糟糕，你应使用可以最大限度减少冲突的散列函数。")]),t._v(" "),a("li",[t._v("散列表的查找、插入和删除速度都非常快。")]),t._v(" "),a("li",[t._v("散列表适合用于模拟映射关系。")]),t._v(" "),a("li",[t._v("一旦填装因子超过0.7，就该调整散列表的长度。")]),t._v(" "),a("li",[t._v("散列表可用于缓存数据（例如，在Web服务器上）。")]),t._v(" "),a("li",[t._v("散列表非常适合用于防止重复。")]),t._v(" "),a("li",[a("strong",[t._v("Java中,只有值的散列表是HashSet,键值对散列表是HashTable")])])]),t._v(" "),a("h2",{attrs:{id:"第六章-广度优先搜索"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第六章-广度优先搜索"}},[t._v("#")]),t._v(" 第六章:广度优先搜索")]),t._v(" "),a("h3",{attrs:{id:"图简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#图简介"}},[t._v("#")]),t._v(" 图简介")]),t._v(" "),a("ul",[a("li",[t._v("假设你要从狮子坪到观音桥,有不同的换乘方案可以到达")]),t._v(" "),a("li",[t._v("首先从起点狮子坪坐一次车就可以到的地方,发现有两个站点,但是并没有观音桥,说明不能一步到达.")]),t._v(" "),a("li",[t._v("然后从这两个站点再做一次车到的地方有三个.")]),t._v(" "),a("li",[t._v("接着这三个站点第一个可以直接开到观音桥,剩下的两个只能开到一下个换乘站.")]),t._v(" "),a("li",[t._v("得到从狮子坪到观音桥最短路径需要三步,这就是"),a("strong",[t._v("最短路径问题")])]),t._v(" "),a("li",[t._v("解决最短路径问题的算法被称为"),a("strong",[t._v("广度优先搜索")])]),t._v(" "),a("li",[t._v("要确定如何从狮子坪到观音桥,有两个步骤\n"),a("ul",[a("li",[t._v("使用图来建立问题模型")]),t._v(" "),a("li",[t._v("使用广度优先搜索解决问题")])])])]),t._v(" "),a("h3",{attrs:{id:"图是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#图是什么"}},[t._v("#")]),t._v(" 图是什么")]),t._v(" "),a("ul",[a("li",[t._v("图由"),a("strong",[t._v("节点")]),t._v("和"),a("strong",[t._v("边")]),t._v("组成。一个节点可能与众多节点直接相连，这些节点被称为"),a("strong",[t._v("邻居")]),t._v("。")]),t._v(" "),a("li",[t._v("图用于模拟不同的东西是如何相连的。")])]),t._v(" "),a("h3",{attrs:{id:"广度优先搜索"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#广度优先搜索"}},[t._v("#")]),t._v(" 广度优先搜索")]),t._v(" "),a("ul",[a("li",[t._v("广度优先搜索是一种用于图的查找算法，可帮助回答"),a("strong",[t._v("两类问题")]),t._v("。\n"),a("ul",[a("li",[a("strong",[t._v("从节点A出发，有前往节点B的路径吗？")])]),t._v(" "),a("li",[a("strong",[t._v("从节点A出发，前往节点B的哪条路径最短？")])])])]),t._v(" "),a("li",[t._v("假如你是个面膜厂老板,这时候就需要找个面膜微商把面膜卖给他")]),t._v(" "),a("li",[t._v("你就要从微信朋友里查找,首先打开你的微信朋友列表,检查每个人看是否是面膜微商")]),t._v(" "),a("li",[t._v("假设没有朋友是,就必须在朋友的朋友中查找")]),t._v(" "),a("li",[t._v("检查每个人时都把其朋友加入名单.")]),t._v(" "),a("li",[t._v("这种算法会搜遍你的关系网,直到找到面膜微商,这就是"),a("strong",[t._v("广度优先搜索算法")])])]),t._v(" "),a("h4",{attrs:{id:"查找最短路径"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查找最短路径"}},[t._v("#")]),t._v(" 查找最短路径")]),t._v(" "),a("ul",[a("li",[t._v("刚才你看到了如何回答第一类问题("),a("code",[t._v("广度算法回答的两类问题")]),t._v(")，下面来尝试回答第二类问题——谁是关系最近的面膜微商。例如，朋友是"),a("strong",[t._v("一度关系")]),t._v("，朋友的朋友是"),a("strong",[t._v("二度关系")]),t._v("。")]),t._v(" "),a("li",[t._v("关系中"),a("strong",[t._v("一度关系胜过二度关系")]),t._v(",二度关系胜过三度关系.所以应该"),a("strong",[t._v("先在一度关系中搜索")]),t._v(",确定没有之后才在二度关系中搜索.广度优先搜索就是这样做的！")]),t._v(" "),a("li",[t._v("而"),a("strong",[t._v("不是像递归一样")]),t._v(",第一个朋友不是就挖他的朋友,然后挖朋友的朋友这样下去.")]),t._v(" "),a("li",[t._v("也可以这样看,一度关系在二度关系前假如查找名单,等于"),a("strong",[t._v("排好队")]),t._v("一度都排在二度之前.")]),t._v(" "),a("li",[t._v("广度优先搜索"),a("strong",[t._v("不仅查找从A到B的路径")]),t._v("，"),a("strong",[t._v("而且找到")]),t._v("的是"),a("strong",[t._v("最短的路径")]),t._v("。")]),t._v(" "),a("li",[t._v("只有按顺序添加查找,才可以实现,因此你需要按添加顺序进行检查,可实现这种目的的数据结构为"),a("strong",[t._v("队列(queue)")])]),t._v(" "),a("li",[a("strong",[t._v("Java中")]),t._v("的"),a("strong",[t._v("队列")]),t._v("为Queue,"),a("strong",[t._v("一般使用LinkedList")]),t._v("初始化为Queue,因为它实现了List和Queue两个接口.")])]),t._v(" "),a("h4",{attrs:{id:"队列"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#队列"}},[t._v("#")]),t._v(" 队列")]),t._v(" "),a("ul",[a("li",[t._v("队列"),a("strong",[t._v("和现实中排队完全相同")]),t._v(",先排队的人先出队,队列"),a("strong",[t._v("类似于栈")]),t._v(","),a("strong",[t._v("不能随机访问")]),t._v("队列中的元素,"),a("strong",[t._v("只支持两种操作")]),t._v(","),a("strong",[t._v("入队")]),t._v("和"),a("strong",[t._v("出队")])]),t._v(" "),a("li",[t._v("这样用队列来表示查找名单,就可以先找完所有一度关系再找二度关系.")]),t._v(" "),a("li",[t._v("队列是先进先出的数据结构,栈是后进先出的数据结构")])]),t._v(" "),a("h3",{attrs:{id:"实现图"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实现图"}},[t._v("#")]),t._v(" 实现图")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("用代码实现图,每个节点与临近节点相连,类似于"),a("code",[t._v("你->Bob")]),t._v(",应该是用"),a("strong",[t._v("散列表")]),t._v("表示这种关系.")])]),t._v(" "),a("li",[a("p",[t._v("散列表"),a("strong",[t._v("在Java中")]),t._v("我们"),a("strong",[t._v("选用")]),t._v("能将键映射到值的"),a("code",[t._v("HashTable")])])]),t._v(" "),a("li",[a("p",[t._v("要把你的节点映射到你的所有朋友,键为你的名字,值为你朋友名字的List集合")])]),t._v(" "),a("li",[a("p",[t._v("效果大概是这样")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hashtable")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" hashtable "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hashtable")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"埼玉"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"杰诺斯"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"吹雪"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦古"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"杰诺斯"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"库赛诺"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"机械大猩猩"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"吹雪"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"龙卷"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"睫毛"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦普"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦古"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"饿狼"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"茶兰子"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦普"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"库赛诺"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"机械大猩猩"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"龙卷"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"睫毛"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦普"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"饿狼"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nhashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"茶兰子"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("顺便提一句,键值对添加顺序不重要,上边代码中上下随便变换顺序都可以")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("散列表是无序的，因此添加键—值对的顺序无关紧要。")])])]),t._v(" "),a("li",[a("p",[t._v("图中有箭头的,如果有节点只有指向自己的箭头,自己没有指向别人的箭头,它就没有领居,这叫"),a("strong",[t._v("有向图（directed graph）")]),t._v(",其中"),a("strong",[t._v("关系是单向")]),t._v("的.")])]),t._v(" "),a("li",[a("p",[t._v("**无向图（undirected graph）**没有箭头，"),a("strong",[t._v("直接相连的节点互为邻居")]),t._v("。")])])]),t._v(" "),a("h3",{attrs:{id:"实现算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实现算法"}},[t._v("#")]),t._v(" 实现算法")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("这个算法将不断执行，直到满足以下条件之一：")]),t._v(" "),a("ul",[a("li",[t._v("找到一位芒果销售商；")]),t._v(" "),a("li",[t._v("队列变成空的，这意味着你的人际关系网中没有芒果销售商。")])])]),t._v(" "),a("li",[a("p",[t._v("有的人因为同时是不同人的朋友,会被加入队列好几次,但是你只需检查一次,检查完就应该标记为已检查,不再检查他")])]),t._v(" "),a("li",[a("p",[t._v("如果不这样做就可能会导致无限循环,比如一开始你查找自己的朋友,查找到了张三,张三不是面膜微商,然后你把张三的朋友添加到搜索队列,其中就有你,然后你检查到自己,又把张三添加到搜索队列.无限循环")])]),t._v(" "),a("li",[a("p",[t._v("最终代码")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BreadthFirstSearch")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hashtable")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" hashtable "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hashtable")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"埼玉"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"杰诺斯"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"吹雪"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦古"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"杰诺斯"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"库赛诺"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"机械大猩猩"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"吹雪"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"龙卷"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"睫毛"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦普"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦古"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"饿狼"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"茶兰子"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦普"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"库赛诺"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"机械大猩猩"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"龙卷"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"睫毛"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦普"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"饿狼"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"茶兰子"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("search")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"埼玉"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("boolean")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("search")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hashtable")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//空队列")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Queue")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" queue "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("LinkedList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//从Hashtable中取到对应的List加入到队列中,不能直接把LIST加入,应该吧List的所有元素按个加入")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            queue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//已检查过")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" already "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//只要队列中的元素没被取光")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("queue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//出队")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" remove "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" queue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("remove")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//只要不是已经检查过的就继续检查")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("already"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("contains")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果是卖家,就返回true")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("isSeller")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"的关系网里有卖家,是"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果不是卖家就把这个人的朋友添加到队列,把这个人记录为已检查")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" hashtable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        queue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                    already"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("remove"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("boolean")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("isSeller")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("contains")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"邦"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])])])]),t._v(" "),a("h3",{attrs:{id:"运行时间-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#运行时间-2"}},[t._v("#")]),t._v(" 运行时间")]),t._v(" "),a("ul",[a("li",[t._v("如果你在你的整个人际关系网中搜索面膜微商，就意味着你将沿每条边前行（记住，边是从一个人到另一个人的箭头或连接），因此运行时间至少为"),a("em",[t._v("O")]),t._v("(边数)。")]),t._v(" "),a("li",[t._v("你还使用了一个队列，其中包含要检查的每个人。将一个人添加到队列需要的时间是固定的，即为"),a("em",[t._v("O")]),t._v("(1)，因此对每个人都这样做需要的总时间为"),a("em",[t._v("O")]),t._v("(人数)。所以，广度优先搜索的运行时间为"),a("em",[t._v("O")]),t._v("(人数 + 边数)，这通常写作"),a("em",[t._v("O")]),t._v("("),a("em",[t._v("V")]),t._v(" + "),a("em",[t._v("E")]),t._v(")，其中"),a("em",[t._v("V")]),t._v("为"),a("strong",[t._v("顶点（vertice）数")]),t._v("，"),a("em",[t._v("E")]),t._v("为"),a("strong",[t._v("边数")]),t._v("。")])]),t._v(" "),a("h3",{attrs:{id:"练习-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-6"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("下面的小图说明了我早晨起床后要做的事情。")])]),t._v(" "),a("li",[a("p",[t._v("该图指出，我不能没刷牙就吃早餐，因此“吃早餐”依赖于“刷牙”。")])]),t._v(" "),a("li",[a("p",[t._v("另一方面，洗澡不依赖于刷牙，因为我可以先洗澡再刷牙。根据这个图，可创建一个列表，指出我需要按什么顺序完成早晨起床后要做的事情：")]),t._v(" "),a("ul",[a("li",[t._v("(1) 起床")]),t._v(" "),a("li",[t._v("(2) 洗澡")]),t._v(" "),a("li",[t._v("(3) 刷牙")]),t._v(" "),a("li",[t._v("(4) 吃早餐")])])]),t._v(" "),a("li",[a("p",[t._v("请注意，“洗澡”可随便移动，因此下面的列表也可行：")]),t._v(" "),a("ul",[a("li",[t._v("(1) 起床")]),t._v(" "),a("li",[t._v("(2) 刷牙")]),t._v(" "),a("li",[t._v("(3) 洗澡")]),t._v(" "),a("li",[t._v("(4) 吃早餐")])])]),t._v(" "),a("li",[a("p",[t._v("6.3 请问下面的三个列表哪些可行、哪些不可行？")])]),t._v(" "),a("li",[a("p",[t._v("6.4 下面是一个更大的图，请根据它创建一个可行的列表。")])]),t._v(" "),a("li",[a("p",[t._v("从某种程度上说，这种列表是有序的。如果任务A依赖于任务B，在列表中任务A就必须在任务B后面。这被称为拓扑排序，使用它可根据图创建一个有序列表。假设你正在规划一场婚礼，并有一个很大的图，其中充斥着需要做的事情，但却不知道要从哪里开始。这时就可使用拓扑排序来创建一个有序的任务列表。")])]),t._v(" "),a("li",[a("p",[t._v("假设你有一个家谱。")])]),t._v(" "),a("li",[a("p",[t._v("这是一个图，因为它由节点（人）和边组成。其中的边从一个节点指向其父母，但所有的边")])]),t._v(" "),a("li",[a("p",[t._v("都往下指。在家谱中，往上指的边不合情理！因为你父亲不可能是你祖父的父亲！")])]),t._v(" "),a("li",[a("p",[t._v("这种图被称为树。树是一种特殊的图，其中没有往后指的边。")])]),t._v(" "),a("li",[a("p",[t._v("6.5 请问下面哪个图也是树？")])])]),t._v(" "),a("h3",{attrs:{id:"小结-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-7"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("广度优先搜索指出是否有从A到B的路径。")])]),t._v(" "),a("li",[a("p",[t._v("如果有，广度优先搜索将找出最短路径。")])]),t._v(" "),a("li",[a("p",[t._v("面临类似于寻找最短路径的问题时，可尝试使用图来建立模型，再使用广度优先搜索来解决问题。")])]),t._v(" "),a("li",[a("p",[t._v("有向图中的边为箭头，箭头的方向指定了关系的方向，例如，"),a("code",[t._v("rama→adit")]),t._v("表示"),a("code",[t._v("rama")]),t._v("欠"),a("code",[t._v("adit")]),t._v("钱。")])]),t._v(" "),a("li",[a("p",[t._v("无向图中的边不带箭头，其中的关系是双向的，例如，"),a("code",[t._v("ross - rachel")]),t._v("表示“"),a("code",[t._v("ross")]),t._v("与"),a("code",[t._v("rachel")]),t._v("约会，而"),a("code",[t._v("rachel")]),t._v("也与"),a("code",[t._v("ross")]),t._v("约会”。")])]),t._v(" "),a("li",[a("p",[t._v("队列是先进先出（FIFO）的。")])]),t._v(" "),a("li",[a("p",[t._v("栈是后进先出（LIFO）的。")])]),t._v(" "),a("li",[a("p",[t._v("你需要按加入顺序检查搜索列表中的人，否则找到的就不是最短路径，因此搜索列表必须是队列。")])]),t._v(" "),a("li",[a("p",[t._v("对于检查过的人，务必不要再去检查，否则可能导致无限循环。")])])]),t._v(" "),a("h2",{attrs:{id:"第七章-狄克斯特拉算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第七章-狄克斯特拉算法"}},[t._v("#")]),t._v(" 第七章:狄克斯特拉算法")]),t._v(" "),a("ul",[a("li",[t._v("在上一章里学会了使用广度优先搜索在图中找出最短路径")]),t._v(" "),a("li",[t._v("然而"),a("strong",[t._v("最短路径不一定是最快路径")]),t._v(",如果给每段路加上时间,会发现有更快的路径.")]),t._v(" "),a("li",[t._v("要找出"),a("strong",[t._v("最快的路径")]),t._v("就要"),a("strong",[t._v("使用")]),t._v("另一种算法--"),a("strong",[t._v("狄克斯特拉算法")])])]),t._v(" "),a("h3",{attrs:{id:"使用狄克斯特拉算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用狄克斯特拉算法"}},[t._v("#")]),t._v(" 使用狄克斯特拉算法")]),t._v(" "),a("ul",[a("li",[t._v("狄克斯特拉算法有"),a("strong",[t._v("4个步骤")]),t._v(" "),a("ul",[a("li",[t._v("找出最便宜的节点,即可在最短时间内前往的节点")]),t._v(" "),a("li",[t._v("对于该节点的邻居,检查是或否有前往它们的更短路径,如果有就更新其开销")]),t._v(" "),a("li",[t._v("重复这个过程,直到对每个节点都这样做了")]),t._v(" "),a("li",[t._v("结算最终路径")])])])]),t._v(" "),a("h3",{attrs:{id:"术语-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#术语-2"}},[t._v("#")]),t._v(" 术语")]),t._v(" "),a("ul",[a("li",[t._v("狄克斯特拉算法用于"),a("strong",[t._v("每条边")]),t._v("都有"),a("strong",[t._v("关联数字")]),t._v("的图,这些数字被称为"),a("strong",[t._v("权重")]),t._v("(weight).")]),t._v(" "),a("li",[t._v("带权重的图称为加权图,不带的称为非加权图")]),t._v(" "),a("li",[t._v("计算"),a("strong",[t._v("非加权图")]),t._v("中的"),a("strong",[t._v("最短路径")]),t._v(",可使用"),a("strong",[t._v("广度优先搜索")])]),t._v(" "),a("li",[t._v("计算"),a("strong",[t._v("加权图")]),t._v("中的"),a("strong",[t._v("最短路径")]),t._v(",可使用"),a("strong",[t._v("狄克斯特拉算法")])]),t._v(" "),a("li",[t._v("图中可能有"),a("strong",[t._v("环")]),t._v(".上一章中提到了有向图和无向图,无向图意味着"),a("strong",[t._v("两个节点互相指向对方")]),t._v(",其实就是环.")]),t._v(" "),a("li",[a("strong",[t._v("无向图中每条边都是一个环,狄克斯特拉算法只适用于有向无环图.")])])]),t._v(" "),a("h3",{attrs:{id:"换钢琴"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#换钢琴"}},[t._v("#")]),t._v(" 换钢琴")]),t._v(" "),a("ul",[a("li",[t._v("这里的例子讲的就是一个以物易物的故事")]),t._v(" "),a("li",[t._v("前面使用的都是术语"),a("code",[t._v("最短路径")]),t._v("的字面意思:计算两点或两人间的最短路径")]),t._v(" "),a("li",[t._v("但这个例子表达的是,"),a("strong",[t._v("最短路径不一定是物理距离,也可能是让某种度量指标最小")]),t._v(".比如在以物易物中额外支付的费用最少.")])]),t._v(" "),a("h3",{attrs:{id:"负权边"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#负权边"}},[t._v("#")]),t._v(" 负权边")]),t._v(" "),a("ul",[a("li",[t._v("负权边指的就是"),a("strong",[t._v("某个边的权重是负值")]),t._v(".")]),t._v(" "),a("li",[t._v("如果"),a("strong",[t._v("有负权边就不能使用狄克斯特拉算法")])]),t._v(" "),a("li",[t._v("这是因为狄克斯特拉算法这样假设：对于处理过的海报节点，没有前往该节点的更短路径。这种假设仅在没有负权边时才成立。")])]),t._v(" "),a("h3",{attrs:{id:"实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实现"}},[t._v("#")]),t._v(" 实现")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("要使用代码实现算法,需要三个散列表")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("graph(图)")]),t._v(" "),a("ul",[a("li",[t._v("包含了所有边以及每条边的权重")]),t._v(" "),a("li",[t._v("最外层是一个HashSet散列表,key为每个节点(包含起点终点),value为另一个散列表,key是最外层散列表代表的节点要到达的邻居节点,比如A->B,B则是这个散列表的key,value则是这两个节点之间的边的权重")])])]),t._v(" "),a("li",[a("p",[t._v("costs(成本)")]),t._v(" "),a("ul",[a("li",[t._v("除起点外到达其它每个节点的成本,也就是权重之和,这里追求的是最小值,成本最低")]),t._v(" "),a("li",[t._v("对于还不知道的开销,将其设置为无穷大.")])]),t._v(" "),a("blockquote",[a("p",[t._v("Java中使用DOUBLE.POSITIVE_INFINITY表示")])]),t._v(" "),a("ul",[a("li",[t._v("这个散列表的key代表所有从起点开始可以到达的节点,value代表到达这个key的最小开销")])])]),t._v(" "),a("li",[a("p",[t._v("parents(父节点关系)")]),t._v(" "),a("ul",[a("li",[t._v("记录除起点外每个节点的父节点是谁,当然前提也是成本最低的情况下的最优选.")]),t._v(" "),a("li",[t._v("这个散列表的key是除了起点外的每个节点,value是这个节点的最优父节点")])])])])]),t._v(" "),a("li",[a("p",[t._v("最后需要一个用于记录处理过的节点的数组.")])]),t._v(" "),a("li",[a("p",[t._v("自我总结")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("狄克斯特拉算法就是计算有向加权图最短路径的,这里的最短路径就是实际意义上的最短,是权重之和的最短而不是边数的最短")])]),t._v(" "),a("li",[a("p",[t._v("在开始算法之前要做很多准备工作,首先准备好所有节点到其它所有邻居的开销值,也就是加权值,首先准备一个大的键值对散列表"),a("code",[t._v("graph")]),t._v(",因为这里有可能存在值为null,所以不能使用Java里的Hashtable,它键值对都不能为null,要使用HashMap,这是专门考虑了null值的重要性后设计的散列表.")])]),t._v(" "),a("li",[a("p",[t._v("这个大的散列表"),a("code",[t._v("graph")]),t._v("中,key为每个节点的名字,包括起点和终点,然后值为另一个键值对散列表,这个散列表中的键为当前graph节点的key的邻居节点,value是graph节点到这个邻居节点的开销,相当于记录了整个图的结构和权重")])]),t._v(" "),a("li",[a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[t._v("graph"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tstart "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t\ta "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//start到邻居a的开销为4")]),t._v("\n\t\tb "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n\t"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\ta "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n\tb "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("然后准备另一个键值对散列表costs,存储最佳开销,实时更新")])]),t._v(" "),a("li",[a("p",[t._v("这个散列表的key为除起点外的所有节点,因为起点到起点不用动,根本没有开销,所谓的最佳开销指的是从起点到该节点的最佳开销,每次检查所有节点时有更优的也就是比当前这个节点在costs散列表中的value更小的时候就更新costs的value.")])]),t._v(" "),a("li",[a("p",[t._v("然后再准备一个键值对散列表parents,存储最佳父节点关系,也是实时更新")])]),t._v(" "),a("li",[a("p",[t._v("这个散列表的key为除起点外所有节点,因为起点没有父节点,和costs一样,每次检查所有节点,发现有更优的从起点到达该节点的路线时,就更新该节点在parents中的父节点的value.")])]),t._v(" "),a("li",[a("p",[t._v("最后再准备一个List存储检查过的节点.")])]),t._v(" "),a("li",[a("p",[t._v("代码")])]),t._v(" "),a("li",[a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("section7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collections")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * @Author lvzhichao\n * @Date 2021/8/2 14:51\n */")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Dickstra")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//所有节点和权重关系散列表")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" graph "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//开销散列表,由起点初始,实时更新")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" costs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//父节点标注散列表,实时更新")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" parents "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//更优的开销")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" new_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//当前开销")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//当前节点所有邻居")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" neighbors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//已处理节点")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" processed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" graph1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" graph2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" graph3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"start"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("graph1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("graph2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("graph3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Double")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("POSITIVE_INFINITY"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"start"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"b"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"start"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBest")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBest")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//costs是起点开始到所有点的开销,自然也包含了每个节点,从全部节点中选出还未处理的节点中最低开销的那个")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" node "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("find_lowest_cost_node")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果挑选出的节点不为null,就一直循环,何时为null?自然是走完所有的节点到终点的时候为null")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//从开销列表获取当前挑选节点的开销")]),t._v("\n            cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取当前挑选节点的邻居")]),t._v("\n            neighbors "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" graph"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果邻居不为空就循环遍历邻居,也是当邻居为终点时不进行")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v("neighbors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" neighbors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keySet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//当前这个节点的开销")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 加上")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 当前这个节点到邻居节点的开销")]),t._v("\n                    new_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" neighbors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果当前节点到达该邻居更近,就更新开销,更新邻居父节点,并把当前节点加入已处理")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//costs.get(s)是原本起点到达这个邻居节点的最优开销,而new_cost是从挑选的节点到达这个邻居节点的开销")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果从当前挑选节点到邻居节点比之前从起点到邻居节点的最优选择开销更小更优则替换邻居节点的父节点和开销")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//等于是优化了到达这个邻居节点的线路")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("new_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("new_cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                        parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//一波邻居的遍历后,等于检查完当前挑选节点的所有邻居,就把挑选节点加入已检查List")]),t._v("\n            processed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//再次从没检查过的所有节点中找到到达终点开销最小的那个,开始循环")]),t._v("\n            node "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("find_lowest_cost_node")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("printWay")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"父节点散列表:"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("find_lowest_cost_node")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" nodes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//设置正无穷大值为初始最低消耗,这样第一个挑选节点进来后可以保证开销一定小于这个值")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),t._v(" lowest_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Double")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("POSITIVE_INFINITY"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//设置一个最低消耗节点为null")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" lowest_cost_node "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" nodes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keySet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//获取开销散列表中当前轮询的节点的开销值")]),t._v("\n            cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" costs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果当前节点的开销小于最低开销并且当前节点不在已检查节点中")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//就把最低开销更新,最低节点更新为当前轮询节点")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//如果轮训完都没有一个符合,那就说明到终点了,最低开销节点就依旧是null,会被方法return回去")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//在getBest方法中的while循环中就不会开始循环,结束算法")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("lowest_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("processed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("contains")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                lowest_cost "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                lowest_cost_node "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" lowest_cost_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("printWay")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" thisNode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" printList "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ArrayList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        printList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"fin"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        printList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("thisNode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("printList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v("parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keySet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("thisNode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v("thisNode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    thisNode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parents"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("thisNode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v("thisNode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        printList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("thisNode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collections")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("reverse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("printList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StringBuilder")]),t._v(" builder "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StringBuilder")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"最短路径为:"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        printList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("forEach")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("->")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            builder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("append")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("append")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"->"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("builder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])])])])])]),t._v(" "),a("h3",{attrs:{id:"小结-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-8"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("广度优先搜索用于在非加权图中查找最短路径。")]),t._v(" "),a("li",[t._v("狄克斯特拉算法用于在加权图中查找最短路径。")]),t._v(" "),a("li",[t._v("仅当权重为正时狄克斯特拉算法才管用。")]),t._v(" "),a("li",[t._v("如果图中包含负权边，请使用贝尔曼-福德算法。")])]),t._v(" "),a("h2",{attrs:{id:"第八章-贪婪算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第八章-贪婪算法"}},[t._v("#")]),t._v(" 第八章:贪婪算法")]),t._v(" "),a("h4",{attrs:{id:"教室调度问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#教室调度问题"}},[t._v("#")]),t._v(" 教室调度问题")]),t._v(" "),a("ul",[a("li",[t._v("假设有一个课程表,里面有按时间循序排列的课程")]),t._v(" "),a("li",[t._v("但是这些课程是交叉的,也就是有些课是在前面课进行了一段时间但又还没结束时开始")]),t._v(" "),a("li",[t._v("现在要让尽可能多的课程安排在某间教室上")]),t._v(" "),a("li",[t._v("也就是说这些课程必须是一个结束另一个才能开始")]),t._v(" "),a("li",[t._v("具体做法如下\n"),a("ul",[a("li",[t._v("选出结束最早的课,这就是这间教室的第一节课")]),t._v(" "),a("li",[t._v("接下来必须选择第一堂课结束后才开始的课,同样选择结束最早的课")]),t._v(" "),a("li",[t._v("重复这样直到找出答案")])])]),t._v(" "),a("li",[t._v("贪婪算法很简单：每步都采取最优的做法。")]),t._v(" "),a("li",[t._v("用专业术语说，就是你"),a("strong",[t._v("每步都选择局部最优解")]),t._v("，"),a("strong",[t._v("最终得到")]),t._v("的就是"),a("strong",[t._v("全局最优解")]),t._v("。")])]),t._v(" "),a("h4",{attrs:{id:"背包问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#背包问题"}},[t._v("#")]),t._v(" 背包问题")]),t._v(" "),a("ul",[a("li",[t._v("假设你是个小偷,背着可以装35kg的包,在商场准备盗窃可装进背包的商品")]),t._v(" "),a("li",[t._v("如果采用贪婪策略\n"),a("ul",[a("li",[t._v("盗窃可装入包中的最贵商品")]),t._v(" "),a("li",[t._v("再盗窃可装入背包的最贵商品,以此类推")])])]),t._v(" "),a("li",[t._v("商场里有三种东西\n"),a("ul",[a("li",[t._v("3000美元的音响.重30kg")]),t._v(" "),a("li",[t._v("2000美院的笔记本电脑,重20kg")]),t._v(" "),a("li",[t._v("1500美元的吉他,重15kg")])])]),t._v(" "),a("li",[t._v("按贪婪算法肯定先拿最贵的音响放到包里,这样一下子就没空间装其他东西了,还浪费了5kg空间")]),t._v(" "),a("li",[t._v("如果你偷笔记本加吉他,总价为3500美元")]),t._v(" "),a("li",[t._v("在这里贪婪策略不能获得最优解")]),t._v(" "),a("li",[t._v("在有些情况下，"),a("strong",[t._v("完美是优秀的敌人")]),t._v("。有时候，你只需找到一个"),a("strong",[t._v("能够大致解决问题")]),t._v("的算法，此时贪婪算法正好可派上用场，因为它们"),a("strong",[t._v("实现起来很容易")]),t._v("，得到的结果又"),a("strong",[t._v("与正确结果相当接近")])])]),t._v(" "),a("h5",{attrs:{id:"练习-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-7"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[t._v("你在一家家具公司工作，需要将家具发往全国各地，为此你需要将箱子装上卡车。每个箱子的尺寸各不相同，你需要尽可能利用每辆卡车的空间，为此你将如何选择要装上卡车的箱子呢？请设计一种贪婪算法。使用这种算法能得到最优解吗？\n"),a("ul",[a("li",[t._v("先把最打尺寸的家具装进去,然后在剩下的家具里找最大的,以此类推直到装不进去.这个算法未必能找到最优解.")])])]),t._v(" "),a("li",[t._v("你要去欧洲旅行，总行程为7天。对于每个旅游胜地，你都给它分配一个价值——表示你有多想去那里看看，并估算出需要多长时间。你如何将这次旅行的价值最大化？请设计一种贪婪算法。使用这种算法能得到最优解吗？\n"),a("ul",[a("li",[t._v("先去价值最大的,然后去剩下的地方离价值最大的,直到没有时间,未必能得到最优解.")])])])]),t._v(" "),a("h4",{attrs:{id:"集合覆盖问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#集合覆盖问题"}},[t._v("#")]),t._v(" 集合覆盖问题")]),t._v(" "),a("ul",[a("li",[t._v("假设有一个广播节目,要让全美50州听众都听到.")]),t._v(" "),a("li",[t._v("在每个广播台播出都要付费,所以要尽量在少得广播台播出.")]),t._v(" "),a("li",[t._v("每个广播台都有覆盖的地区范围,有可能同时覆盖几个州,不同广播台的区域可能有部分重合")]),t._v(" "),a("li",[t._v("如何找出覆盖全美50州的最小广播台集合?\n"),a("ul",[a("li",[t._v("列出每个可能的广播台集合,称为幂集,可能的子集有2的n次方个")]),t._v(" "),a("li",[t._v("在这些集合里选出覆盖全美50州的最小集合")])])]),t._v(" "),a("li",[t._v("由于可能的集合有2的n次方个,所以运行时间为O(2的n次方),随着广播台的增多,需要的时间激增")])]),t._v(" "),a("h3",{attrs:{id:"近似算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#近似算法"}},[t._v("#")]),t._v(" 近似算法")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("使用这种贪婪算法可得到非常接近的值")]),t._v(" "),a("ul",[a("li",[t._v("选出一个广播台,它覆盖了最多的未覆盖州,即时它覆盖了一些已经覆盖的州也没关系")]),t._v(" "),a("li",[t._v("重复第一步直到覆盖所有州.")])])]),t._v(" "),a("li",[a("p",[t._v("这是一种"),a("strong",[t._v("近似算法")]),t._v(",如果获得精确解时间太长,可以使用近似算法,判断其优劣的标准如下")]),t._v(" "),a("ul",[a("li",[t._v("速度有多快")]),t._v(" "),a("li",[t._v("得到的近似解与最优解的接近程度")])])]),t._v(" "),a("li",[a("p",[t._v("在这个例子中，贪婪算法的运行时间为"),a("em",[t._v("O")]),t._v("(n²)，其中"),a("em",[t._v("n")]),t._v("为广播台数量。")])]),t._v(" "),a("li",[a("p",[t._v("代码分析")]),t._v(" "),a("ul",[a("li",[t._v("出于简化考虑就不列太多的州和广播台了.")]),t._v(" "),a("li",[t._v("首先创建一个包含所有州的Set,Set类似于List,但是元素不可重复,"),a("strong",[t._v("states_needed")])]),t._v(" "),a("li",[t._v("然后创建一个HashMap散列表,key为电台名,value为电台覆盖的州组成的Set,"),a("strong",[t._v("stations")])]),t._v(" "),a("li",[t._v("准备一个Set存储最终选择的广播台--"),a("strong",[t._v("final_stations")])]),t._v(" "),a("li",[t._v("为了确定应该使用哪些电台,就要遍历所有电台,选择覆盖了最多的未覆盖州的广播台,存储在"),a("strong",[t._v("best_station")]),t._v("中")]),t._v(" "),a("li",[t._v("设一个集合"),a("strong",[t._v("states_covered")]),t._v(",包含该电台覆盖的所有未覆盖的州,for循环迭代每个广播台确定它是否是最佳广播台,在第一次for循环中它首先为空,然后存储了"),a("strong",[t._v("第一个电台包含的州和当前所有未覆盖的州的交集")]),t._v(",也就是它这个电台中可以被我们收集到的所有州,在第二次for循环中就拿着第一次循环的开始对比,如果未覆盖周数不够大就被替换.直到循环结束就得到最大的")]),t._v(" "),a("li",[a("strong",[t._v("covered")]),t._v("是一个集合，包含同时出现在states_needed(所有未覆盖的州组成的set)和states_for_station(当前for循环遍历到的电台)中的州；换言之，它包含当前广播台覆盖的一系列还未覆盖的州！也就是"),a("strong",[t._v("当前for循环中电台包含的州和当前所有未覆盖的州的交集")]),t._v(",在第一次for循环中covered也就是states_covered,在之后的循环中,只有包含更多的未覆盖州的电台,才可以把自己的covered赋给states_covered.")]),t._v(" "),a("li",[t._v("检查covered的元素个数是否大于states_covered的元素个数,如果大于就把当前循环到的电台赋给"),a("strong",[t._v("best_station")]),t._v(",当前交集covered赋给states_covered")]),t._v(" "),a("li",[t._v("for循环结束后就把best_station添加到最终广播台列表final_stations")]),t._v(" "),a("li",[t._v("由于best_station已经覆盖了一些州,所以就把这些已经覆盖的州从states_needed去掉,这样才能找到下一个拥有最多未覆盖州的电台,不断循环直到states_needed为空")])]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("section8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token import"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("java"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/**\n * 贪婪算法\n * @Author lvzhichao\n * @Date 2021/8/5 15:08\n */")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Greed")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建包含所有的set")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" areaSet "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"江北"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"渝北"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"沙坪坝"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"南岸"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"渝中"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"九龙坡"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"大渡口"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toSet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//包含所有频道的散列表")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" channelMap "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0001"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"江北"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"渝北"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"沙坪坝"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toSet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0002"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"沙坪坝"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"南岸"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"渝中"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toSet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0003"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"渝中"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"九龙坡"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"大渡口"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toSet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0004"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"沙坪坝"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"南岸"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toSet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0005"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Stream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"九龙坡"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"大渡口"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("collect")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Collectors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("toSet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getChannel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("areaSet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getChannel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" areaSet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//最终选定的频道")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Set")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" final_stations "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("areaSet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" best_station "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" states_covered "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" cover "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" station "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keySet")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//清空中间Set拿来求当前遍历频道地区和所有地区的交集")]),t._v("\n                cover"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("clear")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                cover"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("addAll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("areaSet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                cover"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("retainAll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("channelMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("station"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cover"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("states_covered"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("size")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    best_station "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" station"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//不能这样直接=赋予,这样等于是把地址值赋给states_covered")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 让这两个对象states_covered,cover指向了内存中同一个位置,会一起变动")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//states_covered = cover;")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//这样克隆后再赋值才可以")]),t._v("\n                    states_covered "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashSet")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" cover"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("clone")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//只有在最后才减集,这样是以一次while循环减,不然一次for循环全减完了,还玩个屁")]),t._v("\n            areaSet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("removeAll")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("states_covered"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n            final_stations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_station"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" final_stations"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n")])])])])]),t._v(" "),a("h4",{attrs:{id:"np完全问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#np完全问题"}},[t._v("#")]),t._v(" NP完全问题")]),t._v(" "),a("h5",{attrs:{id:"旅行商问题详解"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#旅行商问题详解"}},[t._v("#")]),t._v(" 旅行商问题详解")]),t._v(" "),a("ul",[a("li",[t._v("假如只涉及两个城市,可选择的路线有两条")]),t._v(" "),a("li",[t._v("从A-B,从B-A")]),t._v(" "),a("li",[t._v("由于有些城市有单行线,无法原路返回,可能要绕道才能回去.所以这两条路线不一定相同")]),t._v(" "),a("li",[t._v("有时候旅行商问题是不确定从哪个城市处罚的,比如发快递,是发到这个城市的哪个集散点,这是未知的,所以需要通过计算未履行上找到起点和最佳路线")]),t._v(" "),a("li",[t._v("这和之前的已知出发点运行时间相同,但出发城市未定更容易处理")]),t._v(" "),a("li",[t._v("每增加一个城市,需要计算的路线书都增加")]),t._v(" "),a("li",[t._v("1个城市-1条路线,2个城市-2条路线,3个城市-6条路线,4个城市24条路线....")]),t._v(" "),a("li",[t._v("这被称为阶乘函数,n!=1x2x3x....x(n-1)xn")]),t._v(" "),a("li",[t._v("随着城市增加,可能的路线数增加的非常快,根本无法找出旅行商问题的正确解")]),t._v(" "),a("li",[t._v("这和集合覆盖问题一样,需要计算所有的解,并找出最小/最短的那个,这都属于NP完全问题")]),t._v(" "),a("li",[a("strong",[t._v("NP完全问题的简单定义是，以难解著称的问题")]),t._v("，如旅行商问题和集合覆盖问题。")])]),t._v(" "),a("h5",{attrs:{id:"如何识别np完全问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何识别np完全问题"}},[t._v("#")]),t._v(" 如何识别NP完全问题")]),t._v(" "),a("ul",[a("li",[t._v("NP完全问题无处不在！如果能够判断出要解决的问题属于NP完全问题就好了，这样就不用去寻找完美的解决方案，而是使用近似算法即可。")]),t._v(" "),a("li",[t._v("没办法判断问题是不是NP完全问题，但还是有一些蛛丝马迹可循的。\n"),a("ul",[a("li",[t._v("元素较少时算法的运行速度非常快，但随着元素数量的增加，速度会变得非常慢")]),t._v(" "),a("li",[t._v("涉及“所有组合”的问题通常是NP完全问题。")]),t._v(" "),a("li",[t._v("不能将问题分成小问题，必须考虑各种可能的情况。这可能是NP完全问题。")]),t._v(" "),a("li",[t._v("如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题。")]),t._v(" "),a("li",[t._v("如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题。")]),t._v(" "),a("li",[t._v("如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题。")])])]),t._v(" "),a("li",[t._v("练习\n"),a("ul",[a("li",[t._v("8.6 有个邮递员负责给20个家庭送信，需要找出经过这20个家庭的最短路径。请问这是一个NP完全问题吗？\n"),a("ul",[a("li",[t._v("是")])])]),t._v(" "),a("li",[t._v("8.7 在一堆人中找出最大的朋友圈（即其中任何两个人都相识）是NP完全问题吗？\n"),a("ul",[a("li",[t._v("是")])])]),t._v(" "),a("li",[t._v("8.8 你要制作美国地图，需要用不同的颜色标出相邻的州。为此，你需要确定最少需要使用多少种颜色，才能确保任何两个相邻州的颜色都不同。请问这是NP完全问题吗？\n"),a("ul",[a("li",[t._v("是")])])])])])]),t._v(" "),a("h4",{attrs:{id:"小结-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-9"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("贪婪算法寻找局部最优解，企图以这种方式获得全局最优解。")]),t._v(" "),a("li",[t._v("对于NP完全问题，还没有找到快速解决方案。")]),t._v(" "),a("li",[t._v("面临NP完全问题时，最佳的做法是使用近似算法。")]),t._v(" "),a("li",[t._v("贪婪算法易于实现、运行速度快，是不错的近似算法。")])]),t._v(" "),a("h2",{attrs:{id:"第九章-动态规划"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第九章-动态规划"}},[t._v("#")]),t._v(" 第九章:动态规划")]),t._v(" "),a("h3",{attrs:{id:"背包问题-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#背包问题-2"}},[t._v("#")]),t._v(" 背包问题")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("类似之前的背包问题,假如你是个小偷,有一个4kg容量的包")])]),t._v(" "),a("li",[a("p",[t._v("有三件东西")]),t._v(" "),a("ul",[a("li",[t._v("音响,3000美元,4kg")]),t._v(" "),a("li",[t._v("笔记本,2000美元,3kg")]),t._v(" "),a("li",[t._v("吉他,1500美元,1kg")])])]),t._v(" "),a("li",[a("p",[t._v("要偷走价值最高的商品集合,该怎么做?")])]),t._v(" "),a("li",[a("p",[t._v("如果尝试每一种组合,每增加一件可挑选的商品计算时间都会翻倍,是O(2的n次方)")])]),t._v(" "),a("li",[a("p",[t._v("之前我们学会了找近似解,现在需要找到最优解")])]),t._v(" "),a("li",[a("p",[t._v("那就是使用动态规划:先解决子问题,再逐步解决大问题")])]),t._v(" "),a("li",[a("p",[t._v("每个动态规划算法都从一个网格开始,背包问题的网格如下")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("1")]),t._v(" "),a("th",[t._v("2")]),t._v(" "),a("th",[t._v("3")]),t._v(" "),a("th",[t._v("4")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("吉他1kg")]),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td",[t._v("音响4kg")]),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td",[t._v("笔记本3kg")]),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td")])])])]),t._v(" "),a("li",[a("p",[t._v("各行为商品,各列为不同的背包,表格最初是空的,填充每个表格到满,就找到答案")])]),t._v(" "),a("li",[a("p",[t._v("从第一行开始,这一行我们只有吉他一个商品,考虑当背包容量不同时最多能塞进多少价值的商品,显然吉他1kg,从1-4kg容量的包都只能装下一个吉他,也就是1500美元")])]),t._v(" "),a("li",[a("p",[t._v("这里考虑1,2kg容量的小包就是为了分割大问题为小问题,在背包问题中,最小的包必须是所有商品中重量最小的那个重量,每次容量的提升就是以一个最小重量为单位.")])]),t._v(" "),a("li",[a("p",[t._v("第一行得到的答案是如果有一个4kg容量的包,可装入的商品最大价值为1500美元,随着算法往下执行,将逐步修改最大值")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("1")]),t._v(" "),a("th",[t._v("2")]),t._v(" "),a("th",[t._v("3")]),t._v(" "),a("th",[t._v("4")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("吉他1kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")])]),t._v(" "),a("tr",[a("td",[t._v("音响4kg")]),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td",[t._v("笔记本3kg")]),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td")])])])]),t._v(" "),a("li",[a("p",[t._v("第二行可以偷吉他和音响,"),a("strong",[t._v("每一行可以偷的都为当前行和之前所有行的商品")]),t._v(".")])]),t._v(" "),a("li",[a("p",[t._v("由于音响太重了,所以1kg-3kg的包还是只能装下吉他,但是当容量为4kg时可以装下音响.而且价值3000美元,大于1500,这就更新了最大价值")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("1")]),t._v(" "),a("th",[t._v("2")]),t._v(" "),a("th",[t._v("3")]),t._v(" "),a("th",[t._v("4")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("吉他1kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")])]),t._v(" "),a("tr",[a("td",[t._v("音响4kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("3000")])]),t._v(" "),a("tr",[a("td",[t._v("笔记本3kg")]),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td"),t._v(" "),a("td")])])])]),t._v(" "),a("li",[a("p",[t._v("第三行全可以偷了,笔记本重3kg,所以1-2kg的包还是只能装下吉他,但是到了3kg容量,就替换为更值钱的笔记本,更新为2000美元")])]),t._v(" "),a("li",[a("p",[t._v("对于4kg容量,当前最大价值为3000,如果不偷音响而偷笔记本,只值2000,但是还有1kg空间,可以装吉他,总价3500,这是最佳选择")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("1")]),t._v(" "),a("th",[t._v("2")]),t._v(" "),a("th",[t._v("3")]),t._v(" "),a("th",[t._v("4")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("吉他1kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")])]),t._v(" "),a("tr",[a("td",[t._v("音响4kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("3000")])]),t._v(" "),a("tr",[a("td",[t._v("笔记本3kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("2000")]),t._v(" "),a("td",[t._v("3500")])])])])]),t._v(" "),a("li",[a("p",[t._v("为何计算小背包可装入的商品的最大价值呢？但愿你现在明白了其中的原因！余下了空间时，你可"),a("strong",[t._v("根据这些子问题的答案")]),t._v("来"),a("strong",[t._v("确定余下的空间可装入哪些商品")]),t._v("。")])])]),t._v(" "),a("h4",{attrs:{id:"公式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#公式"}},[t._v("#")]),t._v(" 公式")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("其实背包问题是有公式的,就是")])]),t._v(" "),a("li",[a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//i为行,j为列")]),t._v("\ncell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" = "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                上一个单元格的值(CELL"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("-1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(")"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                当前商品价值+剩余空间价值(CELL"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("-1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j-当前商品重量"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(")\n             "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//取这两个中更大的那个")]),t._v("\n")])])])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("1")]),t._v(" "),a("th",[t._v("2")]),t._v(" "),a("th",[t._v("3")]),t._v(" "),a("th",[t._v("4")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("吉他1kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")])]),t._v(" "),a("tr",[a("td",[t._v("音响4kg")]),t._v(" "),a("td",[t._v("1500"),a("code",[t._v("CELL[i-1][j-当前商品重量]")])]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("3000"),a("code",[t._v("CELL[i-1][j]")])])]),t._v(" "),a("tr",[a("td",[t._v("笔记本3kg")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("1500")]),t._v(" "),a("td",[t._v("2000")]),t._v(" "),a("td",[t._v("3500 "),a("code",[t._v("cell[i][j]")])])])])])]),t._v(" "),a("li",[a("p",[t._v("表格中最后一格为"),a("code",[t._v("cell[3][4]")]),t._v(",要确定它的值,按公式来看先要找到上一个单元格的值"),a("code",[t._v("(CELL[i-1][j])")]),t._v(",也就是"),a("code",[t._v("CELL[3-1][4]")]),t._v("->"),a("code",[t._v("CELL[2][4]")]),t._v(",3000美元")])]),t._v(" "),a("li",[a("p",[t._v("然后再找到剩余空间价值"),a("code",[t._v("(CELL[i-1][j-当前商品重量])")]),t._v(",也就是"),a("code",[t._v("CELL[3-1][4-3]")]),t._v("->"),a("code",[t._v("CELL[2][1]")]),t._v(",1500美元,加上它原本的价值2000美元,等于3500美元")])]),t._v(" "),a("li",[a("p",[t._v("3500>3000,所以最后一格确定为3500")])])]),t._v(" "),a("hr"),t._v(" "),a("ul",[a("li",[t._v("沿着一列往下走,最大价值有可能降低吗?")]),t._v(" "),a("li",[t._v("不可能,每次迭代你都存储当前最大价值,不可能比以前低")])]),t._v(" "),a("h4",{attrs:{id:"行顺序变化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#行顺序变化"}},[t._v("#")]),t._v(" 行顺序变化")]),t._v(" "),a("ul",[a("li",[t._v("行顺序变化不会对表格的结果有任何影响")])]),t._v(" "),a("h4",{attrs:{id:"逐列填充"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#逐列填充"}},[t._v("#")]),t._v(" 逐列填充")]),t._v(" "),a("ul",[a("li",[t._v("改逐行为逐列对于这个问题没有任何影响,对于其它问题可能有影响")])]),t._v(" "),a("h4",{attrs:{id:"增加更小的商品"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#增加更小的商品"}},[t._v("#")]),t._v(" 增加更小的商品")]),t._v(" "),a("ul",[a("li",[t._v("那就需要调整最小容量的背包以及每次扩容的幅度为更小商品的重量")])]),t._v(" "),a("h4",{attrs:{id:"商品的一部分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#商品的一部分"}},[t._v("#")]),t._v(" 商品的一部分")]),t._v(" "),a("ul",[a("li",[t._v("动态规划不能处理一次只拿商品的一部分,比如两斤米你拿一斤")]),t._v(" "),a("li",[t._v("使用贪婪算法可以轻松解决")])]),t._v(" "),a("h4",{attrs:{id:"互相依赖"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#互相依赖"}},[t._v("#")]),t._v(" 互相依赖")]),t._v(" "),a("ul",[a("li",[t._v("假如你需要解决选择去哪几个地方旅行的问题,指标为旅行花费时间以及值得旅行指数")]),t._v(" "),a("li",[t._v("你打算去英国旅行,但是现在添加了几个法国城市,你到这几个地方都需要花费1.5天")]),t._v(" "),a("li",[t._v("这样计算如果是三个法国城市就要4.5天")]),t._v(" "),a("li",[t._v("但实际上这些1.5天里包含了你到法国的路程0.5天,如果你真到了法国,剩下的城市只需要消耗1天,因为你已经在法国的离得就更近了")]),t._v(" "),a("li",[t._v("这种情况动态规划无法建模,动态规划"),a("strong",[t._v("仅当每个子问题都是离散的，即不依赖于其他子问题时")]),t._v("，"),a("strong",[t._v("动态规划")]),t._v("才管用。")])]),t._v(" "),a("hr"),t._v(" "),a("ul",[a("li",[t._v("动态规划算法的设计"),a("strong",[t._v("最多只需合并两个子背包")]),t._v(",不过"),a("strong",[t._v("子背包可能还包含子背包")])]),t._v(" "),a("li",[t._v("这句话的意思就是,之前的行中已经有一个子背包装了好几件商品了,然后和最后一行的子背包合并即可,而不是一个包装一个,一个包装两个,再一个包装三个最后这三个包合并")])]),t._v(" "),a("hr"),t._v(" "),a("ul",[a("li",[a("strong",[t._v("最优解完全可能导致背包不满")]),t._v(",当有一颗钻石3.5kg,值100万,那就算空了0.5kg的空间也肯定装它")])]),t._v(" "),a("hr"),t._v(" "),a("h4",{attrs:{id:"练习-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-8"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("9.2 假设你要去野营。你有一个容量为6磅的背包，需要决定该携带下面的哪些东西。其中每样东西都有相应的价值，价值越大意味着越重要：")]),t._v(" "),a("ul",[a("li",[t._v("水（重3磅，价值10）；")]),t._v(" "),a("li",[t._v("书（重1磅，价值3）")]),t._v(" "),a("li",[t._v("食物（重2磅，价值9）；")]),t._v(" "),a("li",[t._v("夹克（重2磅，价值5）；")]),t._v(" "),a("li",[t._v("相机（重1磅，价值6）。")])])]),t._v(" "),a("li",[a("p",[t._v("请问携带哪些东西时价值最高？")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("1")]),t._v(" "),a("th",[t._v("2")]),t._v(" "),a("th",[t._v("3")]),t._v(" "),a("th",[t._v("4")]),t._v(" "),a("th",[t._v("5")]),t._v(" "),a("th",[t._v("6")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("水（重3磅，价值10）")]),t._v(" "),a("td",[t._v("/")]),t._v(" "),a("td",[t._v("/")]),t._v(" "),a("td",[t._v("10")]),t._v(" "),a("td",[t._v("10")]),t._v(" "),a("td",[t._v("10")]),t._v(" "),a("td",[t._v("10")])]),t._v(" "),a("tr",[a("td",[t._v("书（重1磅，价值3）")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("10√")]),t._v(" "),a("td",[t._v("13")]),t._v(" "),a("td",[t._v("13")]),t._v(" "),a("td",[t._v("13")])]),t._v(" "),a("tr",[a("td",[t._v("食物（重2磅，价值9）")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("9")]),t._v(" "),a("td",[t._v("12")]),t._v(" "),a("td",[t._v("13")]),t._v(" "),a("td",[t._v("19√")]),t._v(" "),a("td",[t._v("22")])]),t._v(" "),a("tr",[a("td",[t._v("夹克（重2磅，价值5）")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("9")]),t._v(" "),a("td",[t._v("12")]),t._v(" "),a("td",[t._v("14")]),t._v(" "),a("td",[t._v("19√")]),t._v(" "),a("td",[t._v("22")])]),t._v(" "),a("tr",[a("td",[t._v("相机（重1磅，价值6）")]),t._v(" "),a("td",[t._v("6")]),t._v(" "),a("td",[t._v("9")]),t._v(" "),a("td",[t._v("15")]),t._v(" "),a("td",[t._v("18")]),t._v(" "),a("td",[t._v("20")]),t._v(" "),a("td",[t._v("25√")])])])])]),t._v(" "),a("li",[a("p",[t._v("水+食物+相机,重量3+2+1=6,价值10+9+6=25")])])]),t._v(" "),a("h3",{attrs:{id:"最长公共子串"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#最长公共子串"}},[t._v("#")]),t._v(" 最长公共子串")]),t._v(" "),a("ul",[a("li",[a("p",[a("strong",[t._v("设计动态规划")]),t._v("方案")]),t._v(" "),a("ul",[a("li",[t._v("每种动态规划解决方案都涉及网格。")]),t._v(" "),a("li",[t._v("单元格中的值通常就是你要优化的值。在前面的背包问题中，单元格的值为商品的价值。")]),t._v(" "),a("li",[t._v("每个单元格都是一个子问题，因此你应考虑如何将问题分成子问题，这有助于你找出网格的坐标轴。")])])]),t._v(" "),a("li",[a("p",[t._v("现在有个问题,用户在网站查询单词fish,不小心输入了hish,这是个不存在的单词,字典里没有")])]),t._v(" "),a("li",[a("p",[t._v("怎么确定他原本要输入的是fish还是vista呢?")])]),t._v(" "),a("li",[a("p",[t._v("需要明确以下问题")]),t._v(" "),a("ul",[a("li",[t._v("单元格中的值是什么？")]),t._v(" "),a("li",[t._v("如何将这个问题划分为子问题？")]),t._v(" "),a("li",[t._v("网格的坐标轴是什么？")])])]),t._v(" "),a("li",[a("p",[t._v("这里单元格中的值就应该是一个数字,两个字符串都包含的最长子串的长度")])]),t._v(" "),a("li",[a("p",[t._v("子问题是比较子串,不是比较hish和fish,而是先比较fis和his")])]),t._v(" "),a("li",[a("p",[t._v("坐标轴很可能就是这两个单词")])]),t._v(" "),a("li",[a("p",[t._v("最终表格如下")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("H")]),t._v(" "),a("th",[t._v("I")]),t._v(" "),a("th",[t._v("S")]),t._v(" "),a("th",[t._v("H")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("F")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("I")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("S")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("H")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("3")])])])])])]),t._v(" "),a("h4",{attrs:{id:"公式-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#公式-2"}},[t._v("#")]),t._v(" 公式")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("如果当前格两个字母不相同,值为0")])]),t._v(" "),a("li",[a("p",[t._v("如果两个字母相同,值为左上角邻居的值加一")])]),t._v(" "),a("li",[a("p",[t._v("伪代码如下")])]),t._v(" "),a("li",[a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word_a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" word_b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tcell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//两个字母相同")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tcell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//两个字母不同")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("查找hish和vista的最长公共子串网格如下")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("V")]),t._v(" "),a("th",[t._v("I")]),t._v(" "),a("th",[t._v("S")]),t._v(" "),a("th",[t._v("T")]),t._v(" "),a("th",[t._v("A")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("H")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("I")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("S")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("H")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])])])])]),t._v(" "),a("li",[a("p",[t._v("背包问题答案总在最后的单元格中,但是"),a("strong",[t._v("最长公共子串问题")]),t._v(","),a("strong",[t._v("答案可能不在最后一个单元格中")])])])]),t._v(" "),a("h4",{attrs:{id:"最长公共子序列"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#最长公共子序列"}},[t._v("#")]),t._v(" 最长公共子序列")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("假如输入的是fosh,原本想输入的是fish还是fort?")])]),t._v(" "),a("li",[a("p",[t._v("使用最长公共子串判断都相同,都是2,但fish和fosh显然更像")])]),t._v(" "),a("li",[a("p",[t._v("这就需要找最长公共子序列")])]),t._v(" "),a("li",[a("p",[t._v("网格如下")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("F")]),t._v(" "),a("th",[t._v("O")]),t._v(" "),a("th",[t._v("S")]),t._v(" "),a("th",[t._v("H")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("F")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")])]),t._v(" "),a("tr",[a("td",[t._v("O")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")])]),t._v(" "),a("tr",[a("td",[t._v("R")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")])]),t._v(" "),a("tr",[a("td",[t._v("T")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")])])])])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("F")]),t._v(" "),a("th",[t._v("O")]),t._v(" "),a("th",[t._v("S")]),t._v(" "),a("th",[t._v("H")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("F")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")])]),t._v(" "),a("tr",[a("td",[t._v("I")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")])]),t._v(" "),a("tr",[a("td",[t._v("S")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("2")])]),t._v(" "),a("tr",[a("td",[t._v("H")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("3")])])])])])]),t._v(" "),a("h5",{attrs:{id:"公式-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#公式-3"}},[t._v("#")]),t._v(" 公式")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("如果两个字母不同,就选择上方和左方邻居中较大的那个")])]),t._v(" "),a("li",[a("p",[t._v("如果两个字母相同,就将当前单元格的值设置为左上方单元格的值加一")])]),t._v(" "),a("li",[a("p",[t._v("伪代码如下")]),t._v(" "),a("div",{staticClass:"language-json extra-class"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[t._v("if(word_a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" == word_b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(")"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tcell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" = cell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("-1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("-1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" + "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(";"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//两个字母相同")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("else"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tcell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" = max(cell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("-1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cell"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("-1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(");"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//两个字母不同")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])]),t._v(" "),a("h4",{attrs:{id:"练习-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-9"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("p",[t._v("9.3 请绘制并填充用来计算blue和clues最长公共子串的网格。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("B")]),t._v(" "),a("th",[t._v("L")]),t._v(" "),a("th",[t._v("U")]),t._v(" "),a("th",[t._v("E")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("C")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("L")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("U")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("0")])]),t._v(" "),a("tr",[a("td",[t._v("E")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("3")])]),t._v(" "),a("tr",[a("td",[t._v("S")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")]),t._v(" "),a("td",[t._v("0")])])])]),t._v(" "),a("h3",{attrs:{id:"小结-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-10"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("需要在给定约束条件下优化某种指标时，动态规划很有用。")]),t._v(" "),a("li",[t._v("问题可分解为离散子问题时，可使用动态规划来解决。")]),t._v(" "),a("li",[t._v("每种动态规划解决方案都涉及网格。")]),t._v(" "),a("li",[t._v("单元格中的值通常就是你要优化的值。")]),t._v(" "),a("li",[t._v("每个单元格都是一个子问题，因此你需要考虑如何将问题分解为子问题。")]),t._v(" "),a("li",[t._v("没有放之四海皆准的计算动态规划解决方案的公式。")])]),t._v(" "),a("h2",{attrs:{id:"第十章-k最近邻算法-knn算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第十章-k最近邻算法-knn算法"}},[t._v("#")]),t._v(" 第十章:K最近邻算法(KNN算法)")]),t._v(" "),a("ul",[a("li",[t._v("假设现有一个水果,让你猜是橙子还是柚子")]),t._v(" "),a("li",[t._v("建立一个二维坐标系\n"),a("ul",[a("li",[t._v("x轴为个头,从小到大")]),t._v(" "),a("li",[t._v("y轴为颜色,由橙到红")])])]),t._v(" "),a("li",[t._v("一般来说橙子又小又橙,柚子又大又红")]),t._v(" "),a("li",[t._v("如果在坐标轴中处于中间地带的水果如何鉴别呢?")]),t._v(" "),a("li",[t._v("一种方法是看它的邻居,抽取三个离它最近的邻居,三个邻居中橙子比柚子多,这个水果很可能是橙子")]),t._v(" "),a("li",[t._v("这就使用了"),a("strong",[t._v("K最近邻")]),t._v("算法"),a("code",[t._v("（k-nearest neighbours，KNN）")]),t._v("进行了分类.")]),t._v(" "),a("li",[t._v("虽然简单但是很有用,对东西分类可以首先尝试.")])]),t._v(" "),a("h3",{attrs:{id:"推荐系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#推荐系统"}},[t._v("#")]),t._v(" 推荐系统")]),t._v(" "),a("ul",[a("li",[t._v("假设你是网飞,要给用户创建一个电影推荐系统")]),t._v(" "),a("li",[t._v("首先把所有用户放到一个图表中,用户再图表中的位置取决于其喜好,因此喜好相似的用户距离相近")]),t._v(" "),a("li",[t._v("假设对电影的喜好,小王,小李,小张和小刘都和小吕差不多")]),t._v(" "),a("li",[t._v("有了这个图表后,推荐系统的逻辑就是只要小王喜欢的电影就推荐给小吕")]),t._v(" "),a("li",[t._v("但有个问题是如何确定两位用户的相似程度")])]),t._v(" "),a("h4",{attrs:{id:"特征抽取"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#特征抽取"}},[t._v("#")]),t._v(" 特征抽取")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("之前的水果是根据个头和颜色比较,并且绘图")])]),t._v(" "),a("li",[a("p",[t._v("在二维坐标图中,想比较有多像就需要"),a("strong",[t._v("计算两点的距离")]),t._v(",使用"),a("strong",[t._v("毕达哥拉斯公式")])]),t._v(" "),a("ul",[a("li",[t._v("$$\n\\sqrt {(x1-x2)²+(y1-y2)²}\n$$")])])]),t._v(" "),a("li",[a("p",[t._v("假设你要对比的是网飞用户,就要用某种形式把他们放到图表中,这就需要把用户转换为一组坐标")])]),t._v(" "),a("li",[a("p",[t._v("我们可以试着采用一种方式,用户注册时要求他们指出对各类电影的喜欢程度")])]),t._v(" "),a("li",[a("table",[a("thead",[a("tr",[a("th"),t._v(" "),a("th",[t._v("小王")]),t._v(" "),a("th",[t._v("小李")]),t._v(" "),a("th",[t._v("小张")]),t._v(" "),a("th",[t._v("小吕")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("喜剧片")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("4")]),t._v(" "),a("td",[t._v("2")]),t._v(" "),a("td",[t._v("5")])]),t._v(" "),a("tr",[a("td",[t._v("动作片")]),t._v(" "),a("td",[t._v("4")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("5")]),t._v(" "),a("td",[t._v("4")])]),t._v(" "),a("tr",[a("td",[t._v("生活片")]),t._v(" "),a("td",[t._v("4")]),t._v(" "),a("td",[t._v("5")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("2")])]),t._v(" "),a("tr",[a("td",[t._v("恐怖片")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("3")]),t._v(" "),a("td",[t._v("5")])]),t._v(" "),a("tr",[a("td",[t._v("爱情片")]),t._v(" "),a("td",[t._v("4")]),t._v(" "),a("td",[t._v("5")]),t._v(" "),a("td",[t._v("1")]),t._v(" "),a("td",[t._v("3")])])])])]),t._v(" "),a("li",[a("p",[t._v("水果使用两个数(2,3)字表示,这里的用户使用五个数字表示(5,4,2,5,3)")])]),t._v(" "),a("li",[a("p",[t._v("这里计算的是五维空间距离,但是计算公式不变")])]),t._v(" "),a("li",[a("p",[t._v("$$\n\\sqrt {(a1-a2)²+(b1-b2)²+(c1-c2)²+(d1-d2)²+(e1-e2)²}\n$$")])])]),t._v(" "),a("h4",{attrs:{id:"练习-10"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习-10"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("ul",[a("li",[a("h2",{attrs:{id:"_10-1-在netflix示例中-你使用距离公式计算两位用户的距离-但给电影打分时-每位用户的标准并不都相同。假设你有两位用户-yogi和pinky-他们欣赏电影的品味相同-但yogi给喜欢的电影都打5分-而pinky更挑剔-只给特别好的电影打5分。他们的品味一致-但根据距离算法-他们并非邻居。如何将这种评分方式的差异考虑进来呢"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_10-1-在netflix示例中-你使用距离公式计算两位用户的距离-但给电影打分时-每位用户的标准并不都相同。假设你有两位用户-yogi和pinky-他们欣赏电影的品味相同-但yogi给喜欢的电影都打5分-而pinky更挑剔-只给特别好的电影打5分。他们的品味一致-但根据距离算法-他们并非邻居。如何将这种评分方式的差异考虑进来呢"}},[t._v("#")]),t._v(" 10.1 在Netflix示例中，你使用距离公式计算两位用户的距离，但给电影打分时，每位用户的标准并不都相同。假设你有两位用户——Yogi和Pinky，他们欣赏电影的品味相同，但Yogi给喜欢的电影都打5分，而Pinky更挑剔，只给特别好的电影打5分。他们的品味一致，但根据距离算法，他们并非邻居。如何将这种评分方式的差异考虑进来呢？")])]),t._v(" "),a("li",[a("p",[t._v("10.2 假设Netflix指定了一组意见领袖。例如，Quentin Tarantino和Wes Anderson就是Netflix的意见领袖，因此他们的评分比普通用户更重要。请问你该如何修改推荐系统，使其偏重于意见领袖的评分呢？")])])]),t._v(" "),a("h4",{attrs:{id:"回归"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#回归"}},[t._v("#")]),t._v(" 回归")]),t._v(" "),a("ul",[a("li",[t._v("假设不只需要推荐电影,还要预测用户会给这部电影打多少分")]),t._v(" "),a("li",[t._v("可以先抽取和这个用户最近的5个人,当然抽多少人这个要视情况决定,多少都可以,所以才叫做K最近邻,K可以是任何值")]),t._v(" "),a("li",[t._v("假如五个人的分数分别为5,4,4,5,3")]),t._v(" "),a("li",[t._v("平均值为4.2,这就是"),a("strong",[t._v("回归")]),t._v(".")]),t._v(" "),a("li",[a("strong",[t._v("KNN做两项基本工作--分类和回归")]),t._v(" "),a("ul",[a("li",[t._v("分类就是编组")]),t._v(" "),a("li",[t._v("回归就是预测结果(如一个数字)")])])])]),t._v(" "),a("h4",{attrs:{id:"挑选合适特征"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#挑选合适特征"}},[t._v("#")]),t._v(" 挑选合适特征")]),t._v(" "),a("ul",[a("li",[t._v("为了推荐电影,需要用户指出对各类电影的喜好程度")]),t._v(" "),a("li",[t._v("如果让用户给一堆小猫图片打分,这对推荐电影显然是个糟糕的推荐引擎,因为和电影品味无关")]),t._v(" "),a("li",[t._v("或者只给妇联三部曲打分,品味也显现不出来")]),t._v(" "),a("li",[t._v("所以KNN挑选特征很重要,所谓合适的特征\n"),a("ul",[a("li",[t._v("与要推荐的电影紧密相关的特征")]),t._v(" "),a("li",[t._v("不偏不倚的特征,如果只是给喜剧片打分,判断不出他们是否喜欢动作片")])])])]),t._v(" "),a("h3",{attrs:{id:"机器学习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#机器学习"}},[t._v("#")]),t._v(" 机器学习")]),t._v(" "),a("h4",{attrs:{id:"ocr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ocr"}},[t._v("#")]),t._v(" OCR")]),t._v(" "),a("ul",[a("li",[t._v("OCR指的是"),a("strong",[t._v("光学字符识别")]),t._v(",意味着你可以拍摄印刷页面的图片,计算机将自动识别出其中的文字")]),t._v(" "),a("li",[t._v("假如有个数字7,如何自动识别这个数字呢?可使用KNN\n"),a("ul",[a("li",[t._v("浏览大量数字图像,把特征提取")]),t._v(" "),a("li",[t._v("遇到新图像,提取特征,再找出它最近的邻居")])])]),t._v(" "),a("li",[t._v("一般来说OCR算法提取线段,点和曲线等特征")]),t._v(" "),a("li",[t._v("OCR的第一步是查看大量数字图像并提取特征,这被称为"),a("strong",[t._v("训练")]),t._v("(training)")])]),t._v(" "),a("h4",{attrs:{id:"创建垃圾邮件过滤器"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#创建垃圾邮件过滤器"}},[t._v("#")]),t._v(" 创建垃圾邮件过滤器")]),t._v(" "),a("ul",[a("li",[t._v("垃圾邮件过滤器使用一种简单算法--"),a("strong",[t._v("朴素贝叶斯分类器")]),t._v(",首先需要使用一些数据对这个分类器进行训练")]),t._v(" "),a("li",[t._v("判断一封邮件是否是垃圾邮件,可研究邮件标题中的每个字词,发现只有某个词在垃圾邮件中出现过")]),t._v(" "),a("li",[t._v("朴素贝叶斯分类器能计算出邮件为垃圾邮件的概率,"),a("strong",[t._v("应用领域与KNN相似")])])]),t._v(" "),a("h3",{attrs:{id:"小结-11"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结-11"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("ul",[a("li",[t._v("KNN用于分类和回归，需要考虑最近的邻居。")]),t._v(" "),a("li",[t._v("分类就是编组。")]),t._v(" "),a("li",[t._v("回归就是预测结果（如数字）。")]),t._v(" "),a("li",[t._v("特征抽取意味着将物品（如水果或用户）转换为一系列可比较的数字。")]),t._v(" "),a("li",[t._v("能否挑选合适的特征事关KNN算法的成败。")])]),t._v(" "),a("h2",{attrs:{id:"每日阅读"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#每日阅读"}},[t._v("#")]),t._v(" 每日阅读")]),t._v(" "),a("ul",[a("li",[t._v("2021年7月12日 1-15")]),t._v(" "),a("li",[t._v("2021年7月13日 15-40")])])])}),[],!1,null,null,null);s.default=e.exports}}]);